{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Notes I made on various topics.</p> <p>The wiki is built with MkDocs and GitHub Pages. It supports inline PlantUML diagrams.</p> <p>Inspired by wiki.nikitavoloboev.xyz &amp; The Blue Book.</p>"},{"location":"#using-the-wiki","title":"Using the wiki","text":"<p>You can quickly search the contents of this wiki above or you can explore the tree view to the left.</p>"},{"location":"Applications/wallabag/","title":"Wallabag","text":""},{"location":"Applications/wallabag/#run-a-console-command-in-the-container","title":"Run a console command in the container","text":"<pre><code>docker exec -it &lt;containerName&gt; /var/www/wallabag/bin/console &lt;command&gt; --env=prod\n</code></pre>"},{"location":"Applications/wallabag/#list-commands","title":"List commands","text":"<pre><code>docker exec -it wallabag /var/www/wallabag/bin/console list --env=prod\n</code></pre>"},{"location":"Applications/wallabag/#get-help-for-a-command","title":"Get help for a command","text":"<pre><code>docker exec -it wallabag /var/www/wallabag/bin/console help &lt;command&gt; --env=prod\n</code></pre>"},{"location":"Applications/wallabag/#initialize-the-database","title":"Initialize the database","text":"<pre><code>docker exec -it wallabag /var/www/wallabag/bin/console wallabag:install --env=prod --no-interaction\n</code></pre>"},{"location":"Applications/wallabag/#migrate-database","title":"Migrate database","text":"<pre><code>docker exec -it wallabag /var/www/wallabag/bin/console doctrine:migrations:migrate --env=prod --no-interaction\n</code></pre>"},{"location":"Applications/wallabag/#list-users","title":"List users","text":"<pre><code>docker exec -it wallabag /var/www/wallabag/bin/console wallabag:user:list --env=prod\n</code></pre>"},{"location":"Applications/wallabag/#create-a-new-user","title":"Create a new user","text":"<pre><code>docker exec -it wallabag /var/www/wallabag/bin/console fos:user:create --env=prod\n</code></pre>"},{"location":"Applications/wallabag/#make-a-user-super-admin","title":"Make a user super admin","text":"<pre><code>docker exec -it wallabag /var/www/wallabag/bin/console fos:user:promote &lt;user&gt; --super --env=prod\n</code></pre>"},{"location":"Applications/wallabag/#demote-and-deactivate-the-initial-wallabag-user","title":"Demote and deactivate the initial wallabag user","text":"<pre><code>docker exec -it wallabag /var/www/wallabag/bin/console fos:user:demote wallabag --super --env=prod\ndocker exec -it wallabag /var/www/wallabag/bin/console fos:user:deactivate wallabag --env=prod\n</code></pre>"},{"location":"Applications/PiHole/add-unbound/","title":"Add Unbound as a recursive DNS Server to the PiHole setup","text":""},{"location":"Applications/PiHole/add-unbound/#why-would-you-want-this","title":"Why would you want this?","text":"<ul> <li>Using a recursive DNS server is more secure, because no third party DNS server will be used and you will not be tracked by your DNS provider</li> <li>The request time will be faster because the DNS server is running locally</li> <li>Unbound will use DNSSEC to verify DNS requests</li> </ul>"},{"location":"Applications/PiHole/add-unbound/#install","title":"Install","text":"<pre><code>sudo apt install unbound\n</code></pre>"},{"location":"Applications/PiHole/add-unbound/#configuration","title":"Configuration","text":"<p>Configure unbound with:</p> <ul> <li>Listen on port 5335</li> <li>TCP &amp; UDP</li> <li>DNSSEC</li> <li>Enable IPv4 &amp; IPv6</li> <li>Ensure privacy of local IP ranges</li> </ul> <pre><code>cat &lt;&lt; EOF &gt; /etc/unbound/unbound.conf.d/pi-hole.conf\nserver:\n    # If no logfile is specified, syslog is used\n    # logfile: \"/var/log/unbound/unbound.log\"\n    verbosity: 0\n\n    # view more statistics\n    extended-statistics: yes\n\n    interface: 127.0.0.1\n    port: 5335\n    do-ip4: yes\n    do-udp: yes\n    do-tcp: yes\n\n    # May be set to yes if you have IPv6 connectivity\n    do-ip6: yes\n\n    # You want to leave this to no unless you have *native* IPv6. With 6to4 and\n    # Terredo tunnels your web browser should favor IPv4 for the same reasons\n    prefer-ip6: no\n\n    # Use this only when you downloaded the list of primary root servers!\n    # If you use the default dns-root-data package, unbound will find it automatically\n    #root-hints: \"/var/lib/unbound/root.hints\"\n\n    # Trust glue only if it is within the server's authority\n    harden-glue: yes\n\n    # Require DNSSEC data for trust-anchored zones, if such data is absent, the zone becomes BOGUS\n    harden-dnssec-stripped: yes\n\n    # Don't use Capitalization randomization as it known to cause DNSSEC issues sometimes\n    # see https://discourse.pi-hole.net/t/unbound-stubby-or-dnscrypt-proxy/9378 for further details\n    use-caps-for-id: no\n\n    # Reduce EDNS reassembly buffer size.\n    # IP fragmentation is unreliable on the Internet today, and can cause\n    # transmission failures when large DNS messages are sent via UDP. Even\n    # when fragmentation does work, it may not be secure; it is theoretically\n    # possible to spoof parts of a fragmented DNS message, without easy\n    # detection at the receiving end. Recently, there was an excellent study\n    # &gt;&gt;&gt; Defragmenting DNS - Determining the optimal maximum UDP response size for DNS &lt;&lt;&lt;\n    # by Axel Koolhaas, and Tjeerd Slokker (https://indico.dns-oarc.net/event/36/contributions/776/)\n    # in collaboration with NLnet Labs explored DNS using real world data from the\n    # the RIPE Atlas probes and the researchers suggested different values for\n    # IPv4 and IPv6 and in different scenarios. They advise that servers should\n    # be configured to limit DNS messages sent over UDP to a size that will not\n    # trigger fragmentation on typical network links. DNS servers can switch\n    # from UDP to TCP when a DNS response is too big to fit in this limited\n    # buffer size. This value has also been suggested in DNS Flag Day 2020.\n    edns-buffer-size: 1232\n\n    # Perform prefetching of close to expired message cache entries\n    # This only applies to domains that have been frequently queried\n    prefetch: yes\n\n    # One thread should be sufficient, can be increased on beefy machines. In reality for most users running on small networks or on a single machine, it should be unnecessary to seek performance enhancement by increasing num-threads above 1.\n    num-threads: 1\n\n    # Ensure kernel buffer is large enough to not lose messages in traffic spikes\n    so-rcvbuf: 1m\n\n    # Ensure privacy of local IP ranges\n    # Needs to be commented out if you have a public dns records (e.g. Cloudflare) resolving to\n    # your local IP. Those records will otherwise be unresolvable.\n    private-address: 192.168.0.0/16\n    private-address: 169.254.0.0/16\n    private-address: 172.16.0.0/12\n    private-address: 10.0.0.0/8\n    private-address: fd00::/8\n    private-address: fe80::/10\nEOF\n</code></pre> <p>Signal PiHole to use this limit</p> <pre><code>cat &lt;&lt; EOF &gt; /etc/dnsmasq.d/99-edns.conf\nedns-packet-max=1232\nEOF\n</code></pre>"},{"location":"Applications/PiHole/add-unbound/#restart-unbound","title":"Restart unbound","text":"<pre><code>sudo systemctl restart unbound\n</code></pre>"},{"location":"Applications/PiHole/add-unbound/#test-unbound","title":"Test unbound","text":""},{"location":"Applications/PiHole/add-unbound/#query","title":"Query","text":"<pre><code>dig google.com @127.0.0.1 -p 5335\n</code></pre>"},{"location":"Applications/PiHole/add-unbound/#dnssec","title":"DNSSec","text":"<p>Get <code>Servfail</code></p> <pre><code>dig sigfail.verteiltesysteme.net @127.0.0.1 -p 5335\n</code></pre> <p>Get <code>NOERROR</code></p> <pre><code>dig sigok.verteiltesysteme.net @127.0.0.1 -p 5335\n</code></pre>"},{"location":"Applications/PiHole/add-unbound/#configure-pihole","title":"Configure PiHole","text":"<p>Now we need to tell PiHole to use unbound as an upstream DNS server.</p> <p>This is done by editing <code>/etc/pihole/setupVars.conf</code> and adding/replacing the following line:</p> <pre><code>PIHOLE_DNS_1=127.0.0.1#5335\nPIHOLE_DNS_2=127.0.0.1#5335\n</code></pre> <p>Restart PiHole</p> <pre><code>systemctl restart pihole-FTL.service\n</code></pre> <p>The PiHole web interface should now show under <code>/admin/settings.php?tab=dns</code> that the upstream DNS server is <code>127.0.0.1#5335</code>.</p> <p>Under <code>/admin/queries.php</code> you should see that the queries are now forwarded to <code>127.0.0.1#5335</code>.</p> <p>If that is not the case, maybe you need to manually save the settings in the web interface under <code>/admin/settings.php?tab=dns</code>.</p>"},{"location":"Applications/PiHole/ha-setup/","title":"PiHole HA Setup","text":""},{"location":"Applications/PiHole/ha-setup/#what-are-we-trying-to-achieve","title":"What are we trying to achieve?","text":"<p>We want to have two PiHole instances that share the same ip address. If one of the instances fails the other one will take over the ip address.</p> <p>They will also share the same gravity database so you only have to update the gravity database on one of the instances.</p>"},{"location":"Applications/PiHole/ha-setup/#why-do-we-want-this","title":"Why do we want this?","text":"<p>If you have a PiHole instance running on a Raspberry Pi and it fails you will have to wait until you can fix it. This means manually changing the dns server on all your devices or trying to change the dhcp server to point to a different dns server. With this setup you will have a backup PiHole instance that will take over the ip address of the primary instance when it fails.</p>"},{"location":"Applications/PiHole/ha-setup/#requirements","title":"Requirements","text":"<ul> <li>Two PiHole instances</li> <li>A ip address that is not used by any other device on your network</li> <li>Both PiHole instances must be on the same network</li> <li>Both PiHole instances must have the same version, check with <code>pihole -v</code>, update with <code>pihole -up</code></li> <li>They may need to be reconfigured with <code>pihole -r</code> to get them to work properly</li> </ul>"},{"location":"Applications/PiHole/ha-setup/#setup-keepalive","title":"Setup keepalive","text":""},{"location":"Applications/PiHole/ha-setup/#install-required-packages","title":"Install required packages","text":"<pre><code>sudo apt install keepalived\n</code></pre>"},{"location":"Applications/PiHole/ha-setup/#configure-keepalived","title":"Configure keepalived","text":"<p>Script to check if local instance is running</p> <pre><code>cat &lt;&lt; EOF &gt; /usr/local/bin/check-local-pihole\n#!/bin/sh\n\nRUNNING=$(ps -aux | grep pihole-FTL | grep -v grep)\nexit $?\nEOF\n\nchmod +x /usr/local/bin/check-local-pihole\n</code></pre>"},{"location":"Applications/PiHole/ha-setup/#configure-keepalived-on-the-primary-instance","title":"Configure keepalived on the primary instance","text":"<pre><code>cat &lt;&lt; EOF &gt; /etc/keepalived/keepalived.conf\nvrrp_script chk_local_pihole {\n    script \"/usr/local/bin/check-local-pihole\" # (1)!\n    interval 5\n    weight -100\n}\n\nglobal_defs {\n  router_id pihole-01 # (2)!\n  script_user root\n  enable_script_security\n}\n\nvrrp_instance PIHOLE {\n  state MASTER # (3)!\n  interface eth0 # (4)!\n  virtual_router_id 20 # (5)!\n  priority 150\n  advert_int 1\n  unicast_src_ip 192.168.3.21 # (6)!\n  unicast_peer {\n    192.168.3.22 # (7)!\n  }\n\n  authentication {\n    auth_type PASS\n    auth_pass piholedns # (8)!\n  }\n\n  virtual_ipaddress {\n    192.168.3.20/23 # (9)!\n  }\n\n  track_script {\n    chk_local_pihole\n  }\n}\nEOF\n</code></pre> <ol> <li>Path to the script that checks if the local instance is running</li> <li>Name of the router</li> <li>State of the instance, MASTER or BACKUP</li> <li>Interface to use</li> <li>virtual_router_id, must be the same on both instances</li> <li>unicast_src_ip, ip address of the local instance</li> <li>unicast_peer, ip address of the remote instance</li> <li>auth_pass, must be the same on both instances</li> <li>virtual_ipaddress, ip address that will be used by the clients and shared between the two instances</li> </ol>"},{"location":"Applications/PiHole/ha-setup/#configure-keepalived-on-the-secondary-instance","title":"Configure keepalived on the secondary instance","text":"<pre><code>cat &lt;&lt; EOF &gt; /etc/keepalived/keepalived.conf\nvrrp_script chk_pihole {\n  script \"/usr/local/bin/check-local-pihole\"\n  interval 1\n  weight -100\n}\n\nglobal_defs {\n  router_id pihole-02\n  script_user root\n  enable_script_security\n}\n\nvrrp_instance PIHOLE {\n  state BACKUP\n  interface eth0\n  virtual_router_id 20\n  priority 140\n  advert_int 1\n  unicast_src_ip 192.168.3.22\n  unicast_peer {\n    192.168.3.21\n  }\n\n  authentication {\n    auth_type PASS\n    auth_pass piholedns\n  }\n\n  virtual_ipaddress {\n    192.168.3.20/23\n  }\n\n  track_script {\n    chk_local_pihole\n  }\n}\nEOF\n</code></pre>"},{"location":"Applications/PiHole/ha-setup/#start-keepalived","title":"Start keepalived","text":"<p>Run on both instances</p> <pre><code>systemctl enable --now keepalived.service\n</code></pre>"},{"location":"Applications/PiHole/ha-setup/#test-keepalived","title":"Test keepalived","text":"<ol> <li>Check if the pihole portal is reachable through the virtual ip address</li> <li>Check if the virtual ip address is assigned to the primary instance by watching the output of <code>ip a</code> on both instances     or looking at the pihole dashboard in the top right corner</li> <li>Restart the pihole service on the primary instance and check if the virtual ip address is assigned to the secondary instance</li> <li>Check if the primary instance will take over the virtual ip address when it is restarted</li> </ol>"},{"location":"Applications/PiHole/ha-setup/#sync-gravity-database","title":"Sync gravity database","text":""},{"location":"Applications/PiHole/ha-setup/#install-required-packages_1","title":"Install required packages","text":"<pre><code>apt update &amp;&amp; apt install sqlite3 sudo git cron rsync ssh\n</code></pre>"},{"location":"Applications/PiHole/ha-setup/#install-gravity-sync-script","title":"Install gravity sync script","text":"<p>We will use gravity-sync to sync the gravity database between the two instances.</p> <p>Install gravity-sync on both instances and follow the instructions.</p> <pre><code>curl -sSL https://raw.githubusercontent.com/vmstan/gs-install/main/gs-install.sh | bash\n</code></pre> <p>You can always reset the configuration with <code>gravity-sync config</code></p>"},{"location":"Applications/PiHole/ha-setup/#push-gravity-database-to-secondary-instance","title":"Push gravity database to secondary instance","text":"<p>Run the following command on the primary instance to push the gravity database to the secondary instance.</p> <pre><code>gravity-sync push\n</code></pre>"},{"location":"Applications/PiHole/ha-setup/#automate-gravity-database-sync","title":"Automate gravity database sync","text":"<p>Run the following command on both instances to create a systemd timer that will sync the gravity database every 5 minutes.</p> <pre><code>gravity-sync automate\n</code></pre> <p>You can check the status of the timer with <code>systemctl status gravity-sync.timer</code>. And you can check the logs with <code>journalctl -u gravity-sync.service</code>.</p> <p>With <code>gravity-sync automate hour</code> the timer will sync the gravity database every hour.</p>"},{"location":"Applications/PiHole/install-unbound-prometheus-exporter/","title":"Install the Unbound Prometheus Exporter","text":""},{"location":"Applications/PiHole/install-unbound-prometheus-exporter/#install","title":"Install","text":""},{"location":"Applications/PiHole/install-unbound-prometheus-exporter/#install-golang-compile-the-exporter","title":"Install golang &amp; compile the exporter","text":"<pre><code>sudo apt update -y\nsudo apt install golang\n</code></pre> <p>Clone, compile &amp; move the exporter to the correct location</p> <pre><code>git clone https://github.com/letsencrypt/unbound_exporter.git\ncd unbound_exporter\ngo build\nsudo install -o root -g root -m 0755 unbound_exporter /usr/local/bin/unbound-exporter\ncd ..\nrm -rf unbound_exporter\n</code></pre>"},{"location":"Applications/PiHole/install-unbound-prometheus-exporter/#create-a-systemd-service","title":"Create a systemd service","text":"<pre><code>cat &lt;&lt; EOF &gt; /etc/systemd/system/unbound-exporter.service\n[Unit]\nDescription=Unbound Prometheus Exporter\nAfter=network.target\n\n[Service]\nType=simple\nUser=root\nGroup=root\nRestart=always\nExecStart=/usr/local/bin/unbound-exporter -web.listen-address \":9167\" -web.telemetry-path \"/metrics\"\n\n[Install]\nWantedBy=multi-user.target\nEOF\n</code></pre>"},{"location":"Applications/PiHole/install-unbound-prometheus-exporter/#start-the-service","title":"Start the service","text":"<pre><code>sudo systemctl daemon-reload\nsudo systemctl enable --now unbound-exporter.service\n</code></pre>"},{"location":"Applications/PiHole/install-unbound-prometheus-exporter/#test-the-exporter","title":"Test the exporter","text":"<pre><code>curl localhost:9167/metrics\n</code></pre>"},{"location":"Blog/Misc/blog-gh-pages-mkdocs/","title":"How to create a blog with GitHub Pages and MkDocs","text":""},{"location":"Blog/Misc/blog-gh-pages-mkdocs/#dockerfile","title":"Dockerfile","text":"<p>Create the Containerfile at <code>Dockerfile</code> or <code>Containerfile</code>.</p> <pre><code>FROM docker.io/ubuntu:focal\n\nRUN : \\\n    &amp;&amp; apt-get update -y \\\n    &amp;&amp; apt-get install -y --no-install-recommends \\\n    python3 \\\n    python3-venv \\\n    python3-pip \\\n    &amp;&amp; rm -rf /var/lib/api/lists*\n\nWORKDIR /src\n\nCOPY requirements.txt .\nENV PATH = /venv/bin:$PATH\n\nRUN : \\\n    &amp;&amp; python3 -m venv /venv \\\n    &amp;&amp; python3 -m pip --no-cache-dir install -r requirements.txt\n\nCOPY . .\n\nWORKDIR /src/blog\n</code></pre>"},{"location":"Blog/Misc/blog-gh-pages-mkdocs/#taskfile","title":"Taskfile","text":"<p>To store some reoccuring tasks we use a Taskfile. To install Task use this link or just use <code>sudo sh -c \"$(curl --location https://taskfile.dev/install.sh)\" -- -d -b /usr/local/bin</code></p> <p>Create the <code>Taskfile.yml</code>.</p> <pre><code># https://taskfile.dev\n\nversion: \"3\"\n\nvars:\n  CONTAINER_NAME: blog.rwxd.eu\n  CURRENT_DIR:\n    sh: pwd\n  SITE_DIR: \"{{.CURRENT_DIR}}/docs/site\"\n\ntasks:\n  default:\n    cmds:\n      - task -l\n    silent: true\n\n  setup:\n    desc: Setup requirements\n    cmds:\n      - python3 -m pip install -r requirements.txt -q\n      - pre-commit install\n    silent: true\n\n  image:\n    desc: builds container image with name blog.rwxd.eu\n    cmds:\n      - podman build -t {{.CONTAINER_NAME}} -f ./Containerfile\n    silent: true\n\n  serve:\n    desc: Serve blog with a container\n    vars:\n      PORT: 8000\n      MOUNT: \"{{.CURRENT_DIR}}/src\"\n    cmds:\n      - task: image\n      - podman run --rm -p {{.PORT}}:8000 -v ./:/src {{.CONTAINER_NAME}} mkdocs serve\n    silent: true\n\n  serve-local:\n    desc: Serve blog local\n    dir: ./blog\n    cmds:\n      - mkdocs serve\n    silent: true\n\n  build:\n    desc: Build blog pages\n    cmds:\n      - task: image\n      - mkdir -p {{.SITE_DIR}}\n      - podman run --rm -v {{.SITE_DIR}}:/src/blog/site {{.CONTAINER_NAME}} sh -c \"mkdocs build\"\n</code></pre>"},{"location":"Blog/Misc/sane-scanbd-canon-5600f/","title":"Sane &amp; scanbd with Canon CanonScan 5600f","text":""},{"location":"Blog/Misc/sane-scanbd-canon-5600f/#installation-on-a-raspbian","title":"Installation on a raspbian","text":"<pre><code>sudo apt install sane sane-utils sanebd\n</code></pre>"},{"location":"Blog/Misc/sane-scanbd-canon-5600f/#configuration","title":"Configuration","text":"<p>Copy sane configuration to scanbd.</p> <pre><code>cp -r /etc/sane.d/* /etc/scanbd/sane.d/\n</code></pre> <p>Modify <code>/etc/sane.d/dll.conf</code> so that only <code>net</code> is uncommented in the configuration.</p> <pre><code># genesys\nnet\n# canon\n</code></pre> <p>Test if the scanner is detected</p> <pre><code>SANE_CONFIG_DIR=/etc/scanbd scanimage -A\n</code></pre> <pre><code>root@scanner:/opt/insaned# SANE_CONFIG_DIR=/etc/scanbd scanimage -L\ndevice 'genesys:libusb:001:004' is a Canon CanoScan 5600F flatbed scanner\n</code></pre>"},{"location":"Blog/Misc/sane-scanbd-canon-5600f/#start-enable-the-service","title":"Start &amp; enable the service","text":"<pre><code>sudo systemctl start scanbd\nsudo systemctl enable scanbd\n</code></pre>"},{"location":"Blog/Misc/sane-scanbd-canon-5600f/#edit-the-button-configuration","title":"Edit the button configuration","text":"<p><code>/etc/scanbd/scanbd.conf</code></p> <p>The <code>scan</code> action runs the <code>test.script</code> per default. The path of the script or the content can be changed.</p> <pre><code>action scan {\n        filter = \"^scan.*\"\n        numerical-trigger {\n               from-value = 1\n               to-value   = 0\n               }\n        desc   = \"Scan to file\"\n        script = \"/usr/local/bin/scan-to-share\"\n       }\n</code></pre> <p>At the bottom</p> <pre><code># devices\n# each device can have actions and functions, you can disable not relevant devices\ninclude(scanner.d/canon.conf)\n</code></pre>"},{"location":"Blog/Misc/sane-scanbd-canon-5600f/#debugging","title":"Debugging","text":"<pre><code>systemctl stop scanbd\nSANE_CONFIG_DIR=/etc/scanbd scanbd -f\n</code></pre> <p>More verbose:</p> <pre><code>systemctl stop scanbd\nSANE_CONFIG_DIR=/etc/scanbd scanbd -f -d7\n</code></pre>"},{"location":"Blog/Misc/sane-scanbd-canon-5600f/#scan-script","title":"Scan script","text":"<pre><code>#!/usr/bin/env bash\nset -x -e -o pipefail\n\nlog_file=\"/var/scans/scan.log\"\necho \"Starting script\" &gt;&gt; \"$log_file\"\n\nresolution=300\nfile_ending=jpg\nformat=jpeg\nmode=color\n\nfile_data=$(date +'%Y_%m_%d-%H_%M_%S')\nfilename=\"$file_data.$file_ending\"\ntemp_path=\"/tmp/$filename\"\ndest_path=\"/var/scans/scanned/$file_data.pdf\"\n\necho \"Destination path \\\"$dest_path\\\"\" &gt;&gt; \"$log_file\"\necho \"Starting scan with resolution $resolution, format $format &amp; mode $mode\" &gt;&gt; \"$log_file\"\n\nexport SANE_CONFIG_DIR=/etc/scanbd\nscanimage --format \"$format\" --resolution=\"$resolution\" --mode \"$mode\" -v -p &gt; \"$temp_path\"\nimg2pdf \"$temp_path\" -o \"$dest_path\"\nrm \"$temp_path\"\nchmod 777 \"$dest_path\"\n</code></pre>"},{"location":"DevOps/Continuous-Integration/Ansible/ansible-runner/","title":"ansible-runner","text":""},{"location":"DevOps/Continuous-Integration/Ansible/ansible-runner/#usage","title":"Usage","text":"<p>Run with docker as process isolation</p> <p><code>ansible-runner run demo -m debug --hosts localhost -a msg=hello --container-image quay.io/ansible/awx-ee -vvvv --process-isolation --process-isolation-executable=docker</code></p>"},{"location":"DevOps/Continuous-Integration/Ansible/ansible-runner/#links","title":"Links","text":"<ul> <li>Using Runner with Execution Environments</li> </ul>"},{"location":"DevOps/Continuous-Integration/Ansible/molecule/","title":"Ansible Molecule","text":"<p>The molecule project helps to develop and test Ansible roles.</p> <p><code>python3 -m pip install molecule</code></p>"},{"location":"DevOps/Continuous-Integration/Ansible/molecule/#usage","title":"Usage","text":"<p>Generate a new role <code>molecule init role &lt;name&gt;</code></p> <p>Init in existing role <code>molecule init scenario</code></p> <p>List drivers <code>molecule drivers</code></p>"},{"location":"DevOps/Continuous-Integration/Ansible/Ansible%20Code%20Snippets/Wait%20for%20X/","title":"Wait for a connection after e. g. a reboot","text":"<pre><code>- name: Wait for port 22\n  wait_for:\n    host: \"{{ ansible_host }}\"\n    port: 22\n    state: started\n    delay: 10\n    sleep: 1\n    connect_timeout: 5\n    timeout: 900\n  delegate_to: 127.0.0.1\n</code></pre>"},{"location":"DevOps/Continuous-Integration/GitLab-CICD/clear_artifacts/","title":"Script to clear GitLab CI/CD Artifacts via the REST API","text":"<pre><code>import requests\nimport json\n\nclass BearerAuth(requests.auth.AuthBase):\n    def __init__(self, token):\n        self.token = token\n    def __call__(self, r):\n        r.headers[\"authorization\"] = \"Bearer \" + self.token\n        return r\n\nproject = '804'\ntoken='ijuiosjdiof'\n\nfor page in range(1, 200):\n    url = f'https://gitlab.com/api/v4/projects/{project}/jobs?per_page=100&amp;page={page}'\n    print(f'Getting jobs from {url}')\n    response = requests.get(url, auth=BearerAuth(token))\n\n    data= json.loads(response.text)\n\n    for item in data:\n        url=f'https://gitlab.com/api/v4/projects/{project}/jobs/{item[\"id\"]}/artifacts'\n        print(f'Running on {url}')\n        response = requests.delete(url, auth=BearerAuth(token))\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Docker/docker-commands/","title":"Docker commands","text":""},{"location":"DevOps/Infrastructure-Solutions/Docker/docker-commands/#stop-things","title":"Stop things","text":""},{"location":"DevOps/Infrastructure-Solutions/Docker/docker-commands/#stop-all-containers","title":"Stop all containers","text":"<pre><code>docker stop $(docker ps -aq)\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Docker/docker-commands/#remove-things","title":"Remove things","text":""},{"location":"DevOps/Infrastructure-Solutions/Docker/docker-commands/#remove-all-containers","title":"Remove all containers","text":"<pre><code>docker rm $(docker ps -aq)\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Docker/docker-commands/#remove-stop-all-containers","title":"Remove &amp; stop all containers","text":"<pre><code>docker rm -f $(docker ps -aq)\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Docker/docker-commands/#all-images","title":"All Images","text":"<pre><code>docker rmi $(docker images -q)\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Docker/docker-commands/#start-docker-daemon-in-debug-mode","title":"Start docker daemon in debug mode","text":"<pre><code>sudo dockerd --debug\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Docker/ssh-keys/","title":"SSH-Keys in a Dockerfile Build","text":""},{"location":"DevOps/Infrastructure-Solutions/Docker/ssh-keys/#python","title":"Python","text":"<p>```Dockerfile</p>"},{"location":"DevOps/Infrastructure-Solutions/Docker/ssh-keys/#install-pip-requirements","title":"install pip requirements","text":"<p>SHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-c\"] RUN : \\     &amp;&amp; eval \"$(ssh-agent -s)\"\\     &amp;&amp; mkdir -p /root/.ssh \\     &amp;&amp; chmod 0700 /root/.ssh \\     &amp;&amp; echo ${GITLAB_SSH_PRIVATE_KEY} | base64 -d &gt;&gt; /root/.ssh/id_rsa \\     &amp;&amp; chmod 0700 /root/.ssh/id_rsa \\     &amp;&amp; ssh-add /root/.ssh/id_rsa \\     &amp;&amp; ssh-keyscan gitlab.com &gt;&gt; /root/.ssh/known_hosts \\     &amp;&amp; chmod 0644 /root/.ssh/known_hosts \\     &amp;&amp; python3 -m venv /venv \\     &amp;&amp; python3 -m pip install --no-cache-dir -r requirements.txt \\     &amp;&amp; rm -f /root/.ssh/id_rsa</p>"},{"location":"DevOps/Infrastructure-Solutions/Kubernetes/ckad/","title":"CKAD - Certified Kubernetes Application Developer","text":""},{"location":"DevOps/Infrastructure-Solutions/Kubernetes/ckad/#books","title":"Books","text":"<ul> <li>Kubernetes in Action by Marko Luksa</li> </ul>"},{"location":"DevOps/Infrastructure-Solutions/Kubernetes/ckad/#free-labs","title":"Free Labs","text":"<ul> <li>https://killercoda.com/killer-shell-ckad</li> <li>https://killercoda.com/killer-shell-cka</li> <li>https://killercoda.com/kubernetes</li> </ul>"},{"location":"DevOps/Infrastructure-Solutions/Kubernetes/ckad/#free-playground","title":"Free Playground","text":"<ul> <li>https://killercoda.com/playgrounds/scenario/ckad</li> </ul>"},{"location":"DevOps/Infrastructure-Solutions/Kubernetes/ckad/#ckad-exam-labs","title":"CKAD Exam Labs","text":"<ul> <li>killer.sh - 2 free labs, with the purchase of the exam</li> </ul>"},{"location":"DevOps/Infrastructure-Solutions/Kubernetes/K3S/raspberry/","title":"K3s on Raspberry","text":""},{"location":"DevOps/Infrastructure-Solutions/Kubernetes/K3S/raspberry/#errors","title":"Errors","text":""},{"location":"DevOps/Infrastructure-Solutions/Kubernetes/K3S/raspberry/#failed-to-find-memory-cgroup-you-may-need-to-add","title":"Failed to find memory cgroup, you may need to add...","text":"<p>Solution</p> <pre><code>sudo vim /boot/firmware/cmdline.txt\n</code></pre> <p>Add <code>cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1</code> into end of the file.</p>"},{"location":"DevOps/Infrastructure-Solutions/Kubernetes/kubectl/delete/","title":"delete all pods from a namespace that are in Error Status","text":"<pre><code>NAMESPACE=test &amp;&amp; kubectl get pods -n $NAMESPACE | grep Error | cut -d' ' -f 1 | xargs kubectl delete pod -n $NAMESPACE\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/aardvark-dns-problems/","title":"aardvark-dns problems (request timed out)","text":"<p>My uptime-kuma instance started throwing <code>ECONNRESET</code> errors.</p> <p>So I tried to investigate the issues with a manual dig and got time outs <pre><code>dig google.com @192.168.3.20\n;; communications error to 192.168.3.20#53: timed out\n;; communications error to 192.168.3.20#53: timed out\n;; communications error to 192.168.3.20#53: timed out\n\n; &lt;&lt;&gt;&gt; DiG 9.18.24 &lt;&lt;&gt;&gt; google.com @192.168.3.20\n;; global options: +cmd\n;; no servers could be reached\n</code></pre></p> <p>The journal showed errors from the aardvark-dns service</p> <pre><code>[root@ap01 ~]# journalctl -f | grep -i dns \nMar 23 23:44:21 ap01 aardvark-dns[2419]: 9296 dns request got empty response\nMar 23 23:44:26 ap01 aardvark-dns[2419]: 9296 dns request got empty response\nMar 23 23:44:26 ap01 aardvark-dns[2419]: 28012 dns request got empty response\nMar 23 23:44:31 ap01 aardvark-dns[2419]: 28012 dns request got empty response\nMar 23 23:44:44 ap01 aardvark-dns[2419]: 44234 dns request got empty response\n</code></pre> <p>After restarting the host there were no more errors in the journal. But some hours forward, they were there again... About 3 error messages per second.</p> <p>I had two services running which were making a lot of dns requests uptime-kuma and prometheus. So I stopped the containers for both services and the error messages.</p> <p>When I started uptime-kuma again, after a few seconds there were some messages in the journal and the application itself showed problems with dns resolution.</p> <p>So again restarting and trying to find out when the problems occur.</p> <pre><code>podman run --rm -ti --network proxy ubuntu bash\napt update -y &amp;&amp; apt install dnsutils -y\nfor i in {1..10000}; do dig google.com +short; done\n</code></pre> <p>After about 30 seconds maybe every 20 dig resulted in an error. And after some minutes the problems showed every fifth dig command.</p> <p>So I wanted debug logs of aardvark-dns. The service gets started with the first podman run command and inherits its log level.</p> <pre><code>[root@ap01 ~]# ps aux | grep aardvark\npodman     18277  0.1  0.1 816992  4540 ?        Ssl  23:32   0:00 /usr/libexec/podman/aardvark-dns --config /tmp/containers-user-2000/containers/networks/aardvark-dns -p 53 run\n\nkill 18277\n\npodman run --rm -ti --debug ubuntu bash\napt update -y &amp;&amp; apt install dnsutils\n\ndig google.com +short\n</code></pre> <p>Now we can see more details in the journal</p> <pre><code>Mar 24 23:34:50 ap01 aardvark-dns[18277]: parsed message \"[54900] parsed message body: google.com. A IN edns: true\"\nMar 24 23:34:50 ap01 aardvark-dns[18277]: request source address: 10.89.0.19:46989\nMar 24 23:34:50 ap01 aardvark-dns[18277]: checking if backend has entry for: \"google.com.\"\nMar 24 23:34:50 ap01 aardvark-dns[18277]: No backend lookup found, try resolving in current resolvers entry\nMar 24 23:34:50 ap01 aardvark-dns[18277]: Not found, forwarding dns request for \"google.com.\"\nMar 24 23:34:50 ap01 aardvark-dns[18277]: 54900 google.com. A IN =&gt; Some(\nMar 24 23:34:50 ap01 aardvark-dns[18277]: [54900] success reponse\nMar 24 23:34:50 ap01 aardvark-dns[18277]: parsed message \"[5383] parsed message body: google.com. A IN edns: true\"\nMar 24 23:34:50 ap01 aardvark-dns[18277]: request source address: 10.89.0.19:32889\nMar 24 23:34:50 ap01 aardvark-dns[18277]: checking if backend has entry for: \"google.com.\"\nMar 24 23:34:50 ap01 aardvark-dns[18277]: No backend lookup found, try resolving in current resolvers entry\nMar 24 23:34:50 ap01 aardvark-dns[18277]: Not found, forwarding dns request for \"google.com.\"\nMar 24 23:34:50 ap01 aardvark-dns[18277]: 48955 dns request got empty response\n</code></pre> <p>Running a tcpdump shows only correct responses</p> <pre><code>tcpdump -nnl host 1.1.1.1 and port 53\n</code></pre> <p>I have installed podman with the copr podman-next repo.</p> <p>Podman wasn't updated on the host long time before the issue happened, but I still wanted to try if the stable podman version shows the same problem.</p> <p>So lets first export the podman volumes to be on the safe side</p> <p><code>export-volumes.sh</code></p> <pre><code>#!/bin/bash\n\nEXPORT_DIR=\"./volumes/\"\nVOLUME_LIST=$(podman volume ls -q)\n\nfor volume in $VOLUME_LIST; do\n    echo \"Exporting volume $volume\"\n    podman volume export $volume -o \"$EXPORT_DIR/$volume.tar\"\ndone\n\necho \"All volumes exported to $EXPORT_DIR\"\n</code></pre> <p>After that I disabled the copr repo</p> <pre><code>[root@ap01 ~]# dnf copr disable copr.fedorainfracloud.org/rhcontainerbot/podman-next\n[root@ap01 ~]# dnf copr list\ncopr.fedorainfracloud.org/rhcontainerbot/podman-next\n\n[root@ap01 ~]# dnf clean all\n</code></pre> <p>Reinstalled podman and rebooted the system</p> <pre><code>dnf remove podman -y &amp;&amp; dnf makecache &amp;&amp; dnf install podman -y\nshutdown -r now\n</code></pre> <p>After the reboot everything worked like it used to.</p> <p>And its there again after about 24 hours.</p> <p>So we open two panels one as root where we tcpdump and in a podman container</p> <pre><code>root@3c6773429be7:/# for i in {1..300}; do dig google.com @pihole.wrage.eu +short &amp;&amp; sleep 1; done \n; &lt;&lt;&gt;&gt; DiG 9.18.18-0ubuntu0.22.04.2-Ubuntu &lt;&lt;&gt;&gt; google.com @pihole.wrage.eu +short\n;; global options: +cmd\n;; no servers could be reached\n\n^C^C;; communications error to 192.168.3.20#53: timed out\n;; communications error to 192.168.3.20#53: timed out\n;; communications error to 192.168.3.20#53: timed out\n\n; &lt;&lt;&gt;&gt; DiG 9.18.18-0ubuntu0.22.04.2-Ubuntu &lt;&lt;&gt;&gt; google.com @pihole.wrage.eu +short\n;; global options: +cmd\n;; no servers could be reached\n\n^C;; communications error to 192.168.3.20#53: timed out\n;; communications error to 192.168.3.20#53: timed out\n;; communications error to 192.168.3.20#53: timed out\n</code></pre> <pre><code>23:14:39.375115 ens18 Out IP ap01.60520 &gt; pi.hole.domain: 33823+ [1au] A? google.com. (51)\n23:14:39.375379 ens18 In  IP pi.hole.domain &gt; ap01.60520: 33823 1/0/1 A 172.217.16.78 (55)\n23:14:44.377509 ens18 Out IP ap01.40087 &gt; pi.hole.domain: 33823+ [1au] A? google.com. (51)\n23:14:44.377824 ens18 In  IP pi.hole.domain &gt; ap01.40087: 33823 1/0/1 A 172.217.16.78 (55)\n23:14:49.382853 ens18 Out IP ap01.44508 &gt; pi.hole.domain: 33823+ [1au] A? google.com. (51)\n23:14:49.383149 ens18 In  IP pi.hole.domain &gt; ap01.44508: 33823 1/0/1 A 172.217.16.78 (55)\n</code></pre> <p>There are clearly answers coming in, but it seems like they are not forwarded to the container</p> <pre><code>[podman@ap01 ~]$ podman unshare --rootless-netns nslookup google.com\nServer:         169.254.0.1\nAddress:        169.254.0.1#53\n\nNon-authoritative answer:\nName:   google.com\nAddress: 172.217.16.78\nName:   google.com\nAddress: 2a00:1450:4005:800::200e\n\n[podman@ap01 ~]$ podman unshare --rootless-netns nslookup google.com @192.168.3.20\nnslookup: couldn't get address for '@192.168.3.20': not found\n[podman@ap01 ~]$ podman unshare --rootless-netns nslookup @192.168.3.20 google.com\n^C\n[podman@ap01 ~]$ podman unshare --rootless-netns nslookup @192.168.3.20 google.com\n;; connection timed out; no servers could be reached\n</code></pre> <pre><code>[root@ap01 ~]# ps aux | grep slirp4netns\nroot       15108  0.0  0.0   3880  2152 pts/0    S+   23:28   0:00 grep --color=auto slirp4netns\n\n[podman@ap01 ~]$ ps aux | grep -i pasta\npodman      2177  1.3  0.5  76264 37864 ?        Ss   23:30   0:01 /usr/bin/pasta --config-net --pid /tmp/containers-user-2000/containers/networks/rootless-netns/rootless-netns-conn.pid --dns-forward 169.254.0.1 -t none -u none -T none -U none --no-map-gw --quiet --netns /tmp/containers-user-2000/containers/networks/rootless-netns/rootless-netns\n</code></pre> <p>@tomorrow try to install podman 4.6.1 with slirp4netns https://github.com/containers/podman/issues/18530</p>"},{"location":"DevOps/Infrastructure-Solutions/Podman/migrate-compose-to-kubefiles/","title":"Migrate from podman-compose to Kubefiles","text":""},{"location":"DevOps/Infrastructure-Solutions/Podman/migrate-compose-to-kubefiles/#overview","title":"Overview","text":"<p>Kubefiles are a way to define a podman pod and containers in a single file. They are similar to docker-compose files, but can also be used with Kubernetes.</p>"},{"location":"DevOps/Infrastructure-Solutions/Podman/migrate-compose-to-kubefiles/#requirements","title":"Requirements","text":"<p>The podman-compose or docker-compose file must be started with <code>podman-compose up -d</code> and the created podman pod should be listed with <code>podman pod ls</code>.</p>"},{"location":"DevOps/Infrastructure-Solutions/Podman/migrate-compose-to-kubefiles/#generate-kubefiles","title":"Generate Kubefiles","text":""},{"location":"DevOps/Infrastructure-Solutions/Podman/migrate-compose-to-kubefiles/#pod","title":"Pod","text":"<p>Get the pod name via <code>podman pod ls</code> and generate the Kubefile with:</p> <pre><code>podman kube generate &lt;pod_name&gt; -f pod.kube.yaml\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/migrate-compose-to-kubefiles/#file-permissions","title":"File permissions","text":"<p>Get the current ids with <code>stat &lt;file&gt;</code> or <code>stat &lt;directory&gt;</code>.</p> <p>Give the permission to the podman user with <code>chown &lt;podman_user&gt;:&lt;podman_group&gt; &lt;file&gt;</code> or <code>chown -R &lt;podman_user&gt;:&lt;podman_group&gt; &lt;directory&gt;</code>.</p> <p>Use podman to change the permission to the uid and gid found with <code>stat</code>.</p> <pre><code>podman unshare chown &lt;uid&gt;:&lt;gid&gt; &lt;file&gt;\n\n# or\n\npodman unshare chown -R &lt;uid&gt;:&lt;gid&gt; &lt;directory&gt;\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/migrate-compose-to-kubefiles/#persistent-volume-claim","title":"Persistent Volume Claim","text":"<p>Get the volume name via <code>podman volume ls</code> and generate the Kubefile with:</p> <pre><code>podman kube generate &lt;volume_name&gt; -f pvc.kube.yaml\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/podman-compose-systemd-files/","title":"Use systemd files with rootless podman-compose","text":"<p>Currently (as of 6/15/2023), podman-compose must be manually installed to use version 1.0.7 (check with podman-compose -v), because pods are not used by default.</p> <pre><code>pip3 install git+https://github.com/containers/podman-compose.git\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/podman-compose-systemd-files/#setup","title":"Setup","text":"<p>Add the rootless podman user to the systemd-journal group to watch logs.</p> <pre><code>usermod -aG systemd-journal podman\n</code></pre> <p>Create the systemd podman-compose unit with root permissions</p> <pre><code>sudo podman-compose systemd --action create-unit\nsudo systemctl daemon-reload\n</code></pre> <p>Change to the directory where your podman-compose file resides.</p> <p>Register the project</p> <pre><code>podman-compose systemd --action register\n\n# or with a different file name than podman-compose.yaml\npodman-compose -f docker-compose.yaml systemd --action register\n</code></pre> <p>Enable and start the systemd service</p> <pre><code>systemctl --user enable --now 'podman-compose@project-name'\n</code></pre> <p>Stop &amp; Start</p> <pre><code>systemctl --user stop 'podman-compose@project-name'\nsystemctl --user start 'podman-compose@project-name'\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/podman-compose-systemd-files/#troubleshooting","title":"Troubleshooting","text":"<p>When the  systemd unit is created you can use</p> <pre><code>podman pod ls\n\npodman pod inspect pod_project-name\n\nsystemctl --user status -l podman-compose@project-name\n\njournalctl --user -xu podman-compose@project-name\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/podman-quadlets/","title":"Podman Quadlets","text":""},{"location":"DevOps/Infrastructure-Solutions/Podman/podman-quadlets/#pre-requisites","title":"Pre-requisites","text":"<p>When using rootless podman a directory under the user's home directory must be created for the quadlet files.</p> <pre><code>mkdir -p ~/.config/containers/systemd\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/podman-quadlets/#container","title":"Container","text":"<p>A container quadlet file must end with <code>.container</code> in the <code>~/.config/containers/systemd</code> directory.</p> <p>Example quadlet file to run a deluge container (<code>deluge.container</code> file):</p> <pre><code>[Install]\nWantedBy=default.target\n\n[Unit]\nAfter=mullvadvpn.service\n\n[Container]\nImage=docker.io/linuxserver/deluge:latest\nVolume=/opt/container/deluge/downloads/:/downloads\nVolume=/opt/container/deluge/config/:/cofnig\n\n[Service]\n# Restart service when sleep finishes\nRestart=always\n# Extend Timeout to allow time to pull the image\nTimeoutStartSec=900\n</code></pre> <p>All the options for the quadlet file can be found in the podman documentation.</p>"},{"location":"DevOps/Infrastructure-Solutions/Podman/podman-quadlets/#start","title":"Start","text":"<pre><code>systemctl --user daemon-reload\nsystemctl --user start deluge\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/podman-quadlets/#logs","title":"Logs","text":"<pre><code>podman logs systemd-deluge\n\njournactl -f | grep deluge\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/setup-rootless/","title":"Podman rootless setup","text":""},{"location":"DevOps/Infrastructure-Solutions/Podman/setup-rootless/#install-podman","title":"Install podman","text":"<pre><code>dnf install -y podman podman-docker\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/setup-rootless/#enable-low-ports","title":"Enable low ports","text":"<pre><code>if ! grep -q \"net.ipv4.ip_unprivileged_port_start=80\" /etc/sysctl.conf; then echo \"net.ipv4.ip_unprivileged_port_start=80\" &gt;&gt; /etc/sysctl.conf; fi\n\n# Reload sysctl\nsysctl --system\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/setup-rootless/#create-user","title":"Create user","text":"<pre><code>useradd -m -s /bin/bash podman\nsudo -iu podman\n</code></pre>"},{"location":"DevOps/Infrastructure-Solutions/Podman/setup-rootless/#create-podman-socket","title":"Create podman socket","text":"<pre><code>if ! grep -q \"loginctl enable-linger\" ~/.bashrc; then echo \"loginctl enable-linger $(whoami)\" &gt;&gt; ~/.bashrc; fi\nif ! grep -q \"$temp\" ~/.bashrc; then echo \"XDG_RUNTIME_DIR=/run/user/$(id -u)\" &gt;&gt; ~/.bashrc; fi\nsource ~/.bashrc\n</code></pre>"},{"location":"DevOps/Infrastructure-as-Code/ArgoCD/cli-cluster-login/","title":"Login with the ArgoCD Cli in the current cluster","text":""},{"location":"DevOps/Infrastructure-as-Code/ArgoCD/cli-cluster-login/#prerequisites","title":"Prerequisites","text":"<ul> <li>ArgoCD is installed in the current cluster</li> <li>ArgoCD Cli is installed on your machine</li> </ul>"},{"location":"DevOps/Infrastructure-as-Code/ArgoCD/cli-cluster-login/#steps","title":"Steps","text":"<pre><code># change the default namespace of your current context to argocd\nkubectl config set-context --current --namespace=argocd\n\nargocd login --core\n</code></pre> <p>Check for access to the API Server</p> <pre><code>argocd app list\n</code></pre>"},{"location":"Misc/DuckDNS%20update%20or%20set%20IP%20script/","title":"DuckDNS update or set IP script","text":"<pre><code>import json\nimport urllib.request as requests\n\nconfig = {\n    \"token\": \"blabla\",\n    \"duck_domain\": \"cloud-test\",\n    \"ipv4\": True,\n    \"ipv6\": True\n    }\n\nipv4URL = 'https://ipv4.ipleak.net/json/'\nipv6URL = 'https://ipv6.ipleak.net/json/'\n\nif config[\"ipv4\"]:\n    request = requests.urlopen(ipv4URL)\n    data = json.load(request)\n    print(f'IPv4: {json.dumps(data[\"ip\"], indent=2)}')\n\n    request = requests.urlopen(f'https://www.duckdns.org/update?domains={config[\"duck_domain\"]}&amp;token={config[\"token\"]}&amp;ip={data[\"ip\"]}')\n    if request.status != 200:\n        print(request.msg)\n\n\nif config[\"ipv6\"]:\n    request = requests.urlopen(ipv6URL)\n    data = json.load(request)\n    print(f'IPv6: {json.dumps(data[\"ip\"], indent=2)}')\n\n    request = requests.urlopen(f'https://www.duckdns.org/update?domains={config[\"duck_domain\"]}&amp;token={config[\"token\"]}&amp;ipv6={data[\"ip\"]}')\n    if request.status != 200:\n        print(request.msg)\n</code></pre>"},{"location":"Misc/container-fuse-mount/","title":"Problems with a podman / docker container that uses an volume on a sshfs / fuse mount","text":"<pre><code>PermissionError: [Errno 13] Permission denied: '/config/deluged.log'\n</code></pre> <p>Uncomment <code>user_allow_other</code> in <code>/etc/fuse.conf and ensure in</code>/etc/fstab<code>that the sshfs mount has the</code>allow_other` flag set.</p>"},{"location":"Misc/digital-gardening/","title":"Digital Gardening","text":""},{"location":"Misc/digital-gardening/#links","title":"Links","text":"<ul> <li>How the blog broke the web</li> </ul>"},{"location":"Misc/jwt-analyzing/","title":"Show content of a JWT token","text":"<pre><code>jwt=\"ey....\"\njq -R 'split(\".\") | .[1] | @base64d | fromjson' &lt;&lt;&lt; \"$jwt\"\n</code></pre>"},{"location":"Misc/openvpn-container-iptables-error/","title":"Problems with iptables in a OpenVPN container; leaking the real IP","text":"<p>I was using the container \"dperson/openvpn-client:latest\" in combination with a deluge container. Which has the <code>--net=container:vpn</code> option to use the same network stack as the vpn container.</p> <p>By using the website https://ipleak.net/ I noticed that my real IP was leaking while testing the torrent client. The torrent client was listed with the VPN ip and the real ip. Using <code>curl ipinfo.io</code> showed only the VPN ip.</p> <p>The host is an AlmaLinux 9.2.</p> <p>In the container logs where the following lines:</p> <pre><code>&gt; docker logs vpn | grep \"ip\\dtables\"\ntables v1.8.4 (legacy): can't initialize iptables table `filter': Table does not exist (do you need to insmod?)\nPerhaps iptables or your kernel needs to be upgraded.\n</code></pre> <p>IP tables version on the host and in the container:</p> <pre><code>&gt; iptables -V\niptables v1.8.8 (nf_tables)\n\n&gt; docker exec vpn iptables -V\niptables v1.8.4 (legacy)\n</code></pre> <p>So the container was using the legacy iptables version. Also visible in the Dockerfile.</p> <p>The nftables_nat modules are loaded, but the legacy iptables_nat modules are not.</p> <pre><code>&gt; lsmod | grep nf_nat\nnf_nat                 57344  3 xt_nat,nft_chain_nat,xt_MASQUERADE\n\n&gt; lsmod | grep \"^ip\\w*table_nat\"\n</code></pre> <p>So we can load the legacy modules with modprobe.</p> <pre><code>&gt; modprobe iptable_nat\n&gt; modprobe ip6table_nat\n</code></pre> <pre><code>&gt; lsmod | grep \"^ip\\w*table_nat\"\n</code></pre> <p>Now the legacy modules are loaded and the error message is gone.</p> <pre><code>&gt; docker restart vpn\n</code></pre> <p>Make the modules persistent.</p> <pre><code>touch /etc/modules-load.d/iptables_nat.conf\nprintf \"iptable_nat\\nip6table_nat\\n\" &gt; /etc/modules-load.d/iptables_nat.conf\n</code></pre> <p>This solution also works when podman is used instead of docker.</p>"},{"location":"Misc/vagrant-ansible-ssh-connection-error/","title":"SSH Connection Error when using Vagrant and Ansible","text":"<p>I got the following error when using Vagrant and the Ansible provisioner: <pre><code>TASK [Install packages] ********************************************************\nfatal: [default]: FAILED! =&gt; {\"changed\": false, \"module_stderr\": \"Shared connection to 192.168.124.116 closed.\\r\\n\", \"module_stdout\": \"\", \"msg\": \"MODULE FAILURE\\nSee stdout/stderr for the exact error\", \"rc\": 137}\n</code></pre></p> <p>This error occured every time I tried to provision the VM with Ansible.</p> <p>With using <code>ansible.verbose = \"vvvvv\"</code> in the Vagrantfile I got the following output:</p> <pre><code>--- snip ---\nmux_client_read_packet: read header failed: Broken pipe\\r\\ndebug2: Received exit status from master 137\\r\\nShared connection to 192.168.124.116 closed.\\r\\n\",\n--- snip ---\n</code></pre> <p>Error code 137 is issued when a process is terminated externally because of its memory consumption.</p> <p>When checking the kernel logs with <code>dmesg</code> I found the following lines:</p> <pre><code>vagrant ssh\ndmesg | grep oom\n[ 1158.525674] Out of memory: Killed process 2428 (dnf) total-vm:479860kB, anon-rss:352668kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:836kB oom_score_adj:0\n[ 6304.776507] python3 invoked oom-killer: gfp_mask=0x140cca(GFP_HIGHUSER_MOVABLE|__GFP_COMP), order=0, oom_score_adj=0\n[ 6304.776529]  oom_kill_process.cold+0xb/0x10\n[ 6304.776637] [  pid  ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name\n[ 6304.776674] oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=/,mems_allowed=0,global_oom,task_memcg=/user.slice/user-1000.slice/session-5.scope,task=python3,pid=2879,uid=0\n[ 6304.776682] Out of memory: Killed process 2879 (python3) total-vm:401128kB, anon-rss:341880kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:816kB oom_score_adj:\n</code></pre> <p>It clearly shows that the process <code>dnf</code> was killed because of the memory consumption.</p> <p>The default Vagrant VM has 512 MB RAM. It seems that this is not enough for the Ansible provisioning.</p> <p>I increased the RAM to 2048 MB and the provisioning worked without any problems.</p> <pre><code>config.vm.provider \"libvirt\" do |libv|\n    libv.memory = \"4096\"\nend\n</code></pre>"},{"location":"Misc/wireguard-vpn-namespace/","title":"Creating a network namespace that uses wireguard vpn","text":"<p>We will setup a network namespace that uses a wireguard vpn. IPv4 and IPv6 will be routed through the vpn. But it can also be used for IPv4 only or IPv6 only.</p> <p>Additionally we want to access an service in the namespace from the host.</p>"},{"location":"Misc/wireguard-vpn-namespace/#bash-script","title":"Bash Script","text":"<pre><code>#!/usr/bin/env bash\n\nset -euo pipefail\n\nNAMESPACE=\"vpn\"\nWG_INTERFACE=\"wg0\"\nWG_CONFIG=\"/etc/wireguard/wg0.conf\"\nWG_IPV4=\"10.65.186.143/32\"\nWG_IPV6=\"fc00:bbbb:bbbb:bb01::2:ba8e/128\"\nVETH_TO_NS_IP=\"10.0.187.4/31\"\nVETH_TO_NS_IPV6=\"fd00:0:187::4/127\"\nVETH_FROM_NS_IP=\"10.0.187.5/31\"\nVETH_FROM_NS_IPV6=\"fd00:0:187::5/127\"\nNAMESERVER=\"10.64.0.1\"\nPODMAN_CONTAINER_PORT=\"8112\"\nIPTABLES_NAT_PORT=\"8112\"\nHOME_SUBNET=\"192.168.2.0/23\"\n\nlog() {\n    echo \"$(date +\"%Y-%m-%d %H:%M:%S\") - $1\"\n}\n\n# Process command-line options\nwhile [[ $# -gt 0 ]]; do\n    case \"$1\" in\n        -v|--verbose)\n            VERBOSE=true\n            set -x\n            ;;\n        *)\n            echo \"Unknown option: $1\"\n            exit 1\n            ;;\n    esac\n    shift\ndone\n\n# Create network namespace\nif ! ip netns list | grep -q \"$NAMESPACE\"; then\n    log \"Creating network namespace: $NAMESPACE\"\n    ip netns add \"$NAMESPACE\"\n    ip -n \"$NAMESPACE\" addr add 127.0.0.1/8 dev lo\n    ip -n \"$NAMESPACE\" addr add ::1/128 dev lo\n    ip -n \"$NAMESPACE\" link set lo up\nelse\n    log \"Network namespace $NAMESPACE already exists.\"\nfi\n\n# Create WireGuard interface\nif ! ip -n \"$NAMESPACE\" link show \"$WG_INTERFACE\" &amp;&gt; /dev/null; then\n    log \"Creating WireGuard interface: $WG_INTERFACE\"\n    ip link add \"$WG_INTERFACE\" type wireguard\n    ip link set \"$WG_INTERFACE\" netns \"$NAMESPACE\"\n    ip netns exec \"$NAMESPACE\" wg setconf \"$WG_INTERFACE\" &lt;(wg-quick strip \"$WG_CONFIG\")\n    ip -n \"$NAMESPACE\" address add \"$WG_IPV4\" dev \"$WG_INTERFACE\"\n    ip -n \"$NAMESPACE\" address add \"$WG_IPV6\" dev \"$WG_INTERFACE\"\n    ip -n \"$NAMESPACE\" link set \"$WG_INTERFACE\" up\nelse\n    log \"WireGuard interface $WG_INTERFACE already exists.\"\nfi\n\n# Add default route for WireGuard interface if it does not exist\nif ! ip -n \"$NAMESPACE\" route show | grep -q \"default dev $WG_INTERFACE\"; then\n    log \"Adding default route for WireGuard interface\"\n    ip -n \"$NAMESPACE\" route add default dev \"$WG_INTERFACE\"\nfi\n\nif ! ip -n \"$NAMESPACE\" -6 route show | grep -q \"default dev $WG_INTERFACE\"; then\n    log \"Adding IPv6 default route for WireGuard interface\"\n    ip -n \"$NAMESPACE\" -6 route add default dev \"$WG_INTERFACE\"\nfi\n\n\n# Configure nameserver\nlog \"Configuring nameserver: $NAMESERVER\"\necho \"nameserver $NAMESERVER\" &gt; \"/etc/netns/$NAMESPACE/resolv.conf\"\n\n# Create veth pair\nif ! ip link show \"to-ns-$NAMESPACE\" &amp;&gt; /dev/null; then\n    log \"Creating veth pair: to-ns-$NAMESPACE and from-ns-$NAMESPACE\"\n    ip link add \"to-ns-$NAMESPACE\" type veth peer name \"from-ns-$NAMESPACE\" netns \"$NAMESPACE\"\n    ip address add \"$VETH_TO_NS_IP\" dev \"to-ns-$NAMESPACE\"\n    ip address add \"$VETH_TO_NS_IPV6\" dev \"to-ns-$NAMESPACE\"\n    ip link set \"to-ns-$NAMESPACE\" up\n    ip -n \"$NAMESPACE\" address add \"$VETH_FROM_NS_IP\" dev \"from-ns-$NAMESPACE\"\n    ip -n \"$NAMESPACE\" address add \"$VETH_FROM_NS_IPV6\" dev \"from-ns-$NAMESPACE\"\n    ip -n \"$NAMESPACE\" link set \"from-ns-$NAMESPACE\" up\nelse\n    log \"Veth pair to-ns-$NAMESPACE and from-ns-$NAMESPACE already exists.\"\nfi\n\n# Add route to home network\nif ! ip -n \"$NAMESPACE\" route show | grep -q \"$HOME_SUBNET\"; then\n   log \"Adding route to home subnet\"\n   IFS='/' read -r IP _ &lt;&lt;&lt; \"$VETH_TO_NS_IP\"\n   ip -n \"$NAMESPACE\" route add \"$HOME_SUBNET\" via \"$IP\"\nfi\n\n# Enable IP forwarding in the host\nlog \"Enabling IP forwarding in the host\"\necho 1 &gt; /proc/sys/net/ipv4/ip_forward\necho 1 &gt; /proc/sys/net/ipv6/conf/all/forwarding\n\nlog \"Setting up port forwarding from the host to the Podman container\"\n\n# Extract only the IP address from the CIDR notation\nIFS='/' read -r IP _ &lt;&lt;&lt; \"$VETH_FROM_NS_IP\"\niptables-nft -t nat -I PREROUTING -p tcp --dport \"$IPTABLES_NAT_PORT\" -j DNAT --to-destination \"$IP:$PODMAN_CONTAINER_PORT\"\niptables-nft -I FORWARD -d \"$IP\" -p tcp --dport \"$PODMAN_CONTAINER_PORT\" -j ACCEPT\n\nIFS='/' read -r IP6 _ &lt;&lt;&lt; \"$VETH_FROM_NS_IPV6\"\nip6tables-nft -t nat -I PREROUTING -p tcp --dport \"$IPTABLES_NAT_PORT\" -j DNAT --to-destination \"$IP6:$PODMAN_CONTAINER_PORT\"\nip6tables-nft -I FORWARD -d \"$IP6\" -p tcp --dport \"$PODMAN_CONTAINER_PORT\" -j ACCEPT\n</code></pre>"},{"location":"Misc/wireguard-vpn-namespace/#systemd-unit","title":"Systemd Unit","text":"<p>Put into <code>/etc/systemd/system/ns-vpn-setup.service</code></p> <pre><code>[Unit]\nDescription=service to setup vpn namespace\nAfter=network-online.target nss-lookup.target\n\n[Service]\nType=oneshot\nExecStart=/usr/local/bin/ns-vpn-setup\nRemainAfterExit=true\nStandardOutput=journal\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"Misc/wireguard-vpn-namespace/#run-the-service","title":"Run the service","text":"<pre><code>systemctl daemon-reload\nsystemctl start ns-vpn-setup\n</code></pre>"},{"location":"Misc/wireguard-vpn-namespace/#tests","title":"Tests","text":""},{"location":"Misc/wireguard-vpn-namespace/#verify-the-wireguard-interface","title":"Verify the wireguard interface","text":"<pre><code># show the interface\nip -n vpn addr show wg0\nip -n vpn route show\n\n# ping cloudflare\nip netns exec vpn ping 1.1.1.1\nip netns exec vpn ping 2606:4700:4700::1111\n</code></pre>"},{"location":"Misc/wireguard-vpn-namespace/#test-the-connection-between-the-namespaces","title":"Test the connection between the namespaces:","text":"<pre><code>ping -c 1 10.0.187.5\nping -c 1 fd00:0:187::5\n\nip netns exec vpn ping -c 1 10.0.187.4\nip netns exec vpn ping -c 1 fd00:0:187::4\n</code></pre>"},{"location":"Misc/wireguard-vpn-namespace/#test-dns-server","title":"Test DNS Server","text":"<pre><code># verify resolving\nip netns exec vpn curl -4 https://ipv4.ipleak.net/json/\nip netns exec vpn curl -6 https://ipv6.ipleak.net/json/\n\n# show which dns server is actually used\nsession=$(openssl rand -hex 20)\nrandom=$(openssl rand -hex 10)\nip netns exec vpn curl -4 -s \"https://$session-$random.ipleak.net/dnsdetection/\"\nip netns exec vpn curl -6 -s \"https://$session-$random.ipleak.net/dnsdetection/\"\n</code></pre>"},{"location":"Misc/wireguard-vpn-namespace/#example-podman-pod","title":"Example Podman Pod","text":"<p>Quadlet file in <code>/etc/containers/systemd/deluge.kube</code></p> <p>Notice the <code>After</code> and <code>Network</code> directives.</p> <pre><code>[Install]\nWantedBy=default.target\n\n[Unit]\nAfter=ns-vpn-setup.service\n\n[Kube]\nYaml=/opt/container/deluge/deluge.kube.yaml\nNetwork=ns:/var/run/netns/vpn\n\n[Service]\n# Restart service when sleep finishes\nRestart=always\n# Extend Timeout to allow time to pull the image\nTimeoutStartSec=900\n</code></pre>"},{"location":"Networking/Misc/nfcapd/","title":"NFCAPD (NetFlow Capture Daemon)","text":""},{"location":"Networking/Misc/nfcapd/#show-running-captures","title":"Show running captures","text":"<pre><code>sudo ps -e -o command | grep nfcapd\n</code></pre>"},{"location":"Networking/Misc/nfcapd/#edit-configuration","title":"Edit configuration","text":"<p>Find the nfsen configuration first</p> <pre><code>sudo find / -type f -name \"nfsen.conf\"\n</code></pre> <pre><code>vim /opt/etc/nfsen.conf\n</code></pre>"},{"location":"Networking/Misc/nfcapd/#links","title":"Links","text":"<ul> <li>https://manpages.ubuntu.com/manpages/bionic/man1/nfcapd.1.html</li> </ul>"},{"location":"Networking/Misc/traffic-billing/","title":"Traffic Billing","text":""},{"location":"Networking/Misc/traffic-billing/#95th-percentile-billing","title":"95th Percentile Billing","text":"<p>The 95th percentile is a commonly used statistical measure to discard the top 5% of the highest values in a dataset. In network traffic calculation, it's a method used to determine the bandwidth billing rate, highlighting the regular usage while excluding rare usage spikes.</p>"},{"location":"Networking/Misc/traffic-billing/#how-it-works","title":"How it works","text":"<ul> <li>Every 5 minutes, the traffic flow rate (usually in bits per second) is measured.</li> <li>These values are then stored and sorted from lowest to highest over a month.</li> <li>The top 5% of the data points (the highest values) are discarded.</li> <li>The highest remaining value is the 95th percentile, and this rate is used as the billing rate for the entire month.</li> </ul>"},{"location":"Networking/Misc/traffic-billing/#advantages","title":"Advantages","text":"<ul> <li>Fairness: It does not penalize customers for infrequent spikes in traffic.</li> <li>Predictability: Customers have a more consistent billing rate from month to month.</li> <li>Encourages Efficient Use: Users can manage their bandwidth and understand their regular usage without the fear of occasional spikes in traffic inflating their bills.</li> </ul>"},{"location":"Networking/Misc/traffic-billing/#disadvantages","title":"Disadvantages","text":"<ul> <li>Potentially Confusing: Those unfamiliar with the method may find their billing unpredictable initially.</li> <li>Not Reflective of Total Volume: It doesn't bill based on the total amount of data transferred, only the regular rate of transfer.</li> </ul>"},{"location":"Networking/Misc/traffic-billing/#example","title":"Example","text":"<pre><code>def calculate_95th_percentile(data):\n    data.sort()  # Step 1: Sort the data\n    index = 0.95 * len(data)  # Step 2: Determine the 95th percentile index\n\n    # Step 3: Get the value\n    if index.is_integer():\n        return data[int(index)-1]  # Python indices are 0-based\n    else:\n        return data[int(round(index))-1]\n\n# Example data: Traffic measurements (in Mbps) every 5 minutes for a day (288 measurements for 24 hours)\ntraffic_data = [random.randint(50, 200) for _ in range(288)]  # Random traffic data between 50 Mbps and 200 Mbps\n\npercentile_value = calculate_95th_percentile(traffic_data)\nprint(f\"95th Percentile Value: {percentile_value} Mbps\")\n</code></pre>"},{"location":"Networking/NSX-T/NSX-T%20Links/","title":"NSX-T Links","text":"<ul> <li>NSX-T Ninja</li> <li>Command Reference from Simon Greaves</li> </ul>"},{"location":"Networking/containerlab/cumulus/","title":"Cumulus on Containerlab","text":""},{"location":"Networking/containerlab/cumulus/#usage","title":"Usage","text":""},{"location":"Networking/containerlab/cumulus/#cvx","title":"CVX","text":"<p>Container Image: docker.io/networkop/cx:5.1.0 Username: root Password: root</p>"},{"location":"Networking/containerlab/ssh/","title":"SSH into Containerlab devices","text":""},{"location":"Networking/containerlab/ssh/#ssh-config","title":"SSH Config","text":"<p><code>$HOME/.ssh/config</code></p> <pre><code>host clab-*\n    StrictHostKeyChecking no\n    UserKnownHostsFile /dev/null\n</code></pre>"},{"location":"Operating-Systems/Android/apps/shelter/","title":"Shelter","text":"<p>Shelter is a Free and Open-Source (FOSS) app that leverages the \"Work Profile\" feature of Android to provide an isolated space that you can install or clone apps into. https://github.com/PeterCxy/Shelter</p>"},{"location":"Operating-Systems/Android/apps/shelter/#links","title":"Links","text":"<ul> <li>F-Droid Package</li> </ul>"},{"location":"Operating-Systems/Linux/X-Forwarding/","title":"X-Forwarding with Windows through SSH","text":""},{"location":"Operating-Systems/Linux/X-Forwarding/#setup","title":"Setup","text":"<p>Install VcXsrv</p> <p>Start <code>XLaunch</code> with enabled clipboard and monitor 1</p> <p>Set the Windows environment variable <code>DISPLAY=\"127.0.0.1:1.0\"</code></p> <p>Connect through SSH with the <code>-Y</code> option.</p>"},{"location":"Operating-Systems/Linux/X-Forwarding/#check-if-it-works","title":"Check if it works","text":"<p>Linux script to check working connection:</p> <pre><code>#!/usr/bin/env bash\n\nif ! timeout 3s xset q &amp;&gt;/dev/null; then\n    echo \"No X server at \\$DISPLAY [$DISPLAY]\" &gt;&amp;2\n    exit 1\nfi\n\necho \"Seems to work :)\"\n</code></pre>"},{"location":"Operating-Systems/Linux/CLI/htpasswd/","title":"htpasswd","text":""},{"location":"Operating-Systems/Linux/CLI/htpasswd/#hash-bcrypt-with-input","title":"Hash BCrypt with input","text":"<pre><code>htpasswd -B -n username\n</code></pre>"},{"location":"Operating-Systems/Linux/CLI/htpasswd/#run-with-a-container","title":"Run with a container","text":"<pre><code>docker run --rm -it httpd:latest htpasswd -B -n username\n</code></pre>"},{"location":"Operating-Systems/Linux/CLI/iotop/","title":"iotop","text":""},{"location":"Operating-Systems/Linux/CLI/iotop/#watch-processes-accumulated","title":"Watch processes accumulated","text":"<pre><code>iotop -oPa\n</code></pre>"},{"location":"Operating-Systems/Linux/CLI/ssh/","title":"SSH","text":""},{"location":"Operating-Systems/Linux/CLI/ssh/#jump-host","title":"Jump host","text":"<p>Use another system to tunnel the traffic trough: <pre><code>ssh -J other.host original.host\n</code></pre></p>"},{"location":"Operating-Systems/Linux/CLI/ssh/#socks-proxy","title":"SOCKS Proxy","text":"<pre><code>ssh -D 1337 -C $USER@&lt;target&gt;\n</code></pre>"},{"location":"Operating-Systems/Linux/CLI/tee/","title":"Tee","text":"<p>With <code>tee</code> it is possible to read from standard input and write to standard output and files (or commands) at the same time.</p>"},{"location":"Operating-Systems/Linux/CLI/tee/#usage","title":"Usage","text":"<p>Log into file and stdout: <code>foo | tee output.file</code></p> <p>Append to a file: <code>foo | tee -a output.file</code></p> <p>Include stderr: <code>foo 2&gt;&amp;1 | tee output.file</code></p> <p><code>2&gt;&amp;1</code> redirects channel 2 (stderr/standard error) into channel 1 (stdout/standard output), such that both is written as stdout</p>"},{"location":"Operating-Systems/Linux/CLI/watch/","title":"watch","text":"<p>Execute a program periodically, showing output in fullscreen.</p>"},{"location":"Operating-Systems/Linux/CLI/watch/#usage","title":"Usage","text":"<p><code>watch du -sh file</code></p> <p>Custom interval in seconds (defaults to every 2 seconds): <code>watch -n 1 du -sh file</code></p>"},{"location":"Operating-Systems/Linux/Misc/NetworkManager/","title":"NetworkManager","text":""},{"location":"Operating-Systems/Linux/Misc/NetworkManager/#wlan","title":"WLAN","text":""},{"location":"Operating-Systems/Linux/Misc/NetworkManager/#autoconnect","title":"Autoconnect","text":"<pre><code>nmcli connection modify &lt;name&gt; connection.autoconnect yes\n</code></pre> <pre><code>nmcli connection modify &lt;name&gt; 802-11-wireless-security.psk &lt;psk&gt;\n</code></pre> <pre><code>nmcli connection up &lt;name&gt;\n</code></pre>"},{"location":"Operating-Systems/Linux/Misc/Time/","title":"Time","text":""},{"location":"Operating-Systems/Linux/Misc/Time/#list-timezone","title":"List timezone","text":"<p><code>timedatectl list-timezones</code></p>"},{"location":"Operating-Systems/Linux/Misc/Time/#change-timezone","title":"Change timezone","text":"<p><code>sudo timedatectl set-timezone Europe/Berlin</code></p>"},{"location":"Operating-Systems/Linux/Misc/cron/","title":"Cron","text":""},{"location":"Operating-Systems/Linux/Misc/cron/#cron-with-error-mails","title":"Cron with error mails","text":"<p>Install chronic</p> <pre><code>apt install moreutils\n</code></pre> <p>/etc/cron.d/01-example-cron</p> <pre><code>#!/usr/bin/env bash\nSHELL=/bin/bash\nPATH=/sbin:/bin:/usr/sbin:/usr/bin/usr/local/bin\nMAILTO=root,my-mail@example.org\n\n0 0 * * * root chronic /usr/local/bin/backup\n</code></pre>"},{"location":"Operating-Systems/Linux/Misc/cryptsetup/","title":"Cryptsetup","text":"<pre><code># format the disk with the luks structure\ncryptsetup luksFormat /dev/sda4\n\n# open the encrypted partition and map it to /dev/mapper/cryptroot\ncryptsetup luksOpen /dev/sda4 cryptroot\n\n# format as usual\nmkfs.ext4 -L nixos /dev/mapper/cryptroot\n</code></pre>"},{"location":"Operating-Systems/Linux/Misc/window-names/","title":"Show window names","text":"<p>Run the following command, after that click on a window to see its name</p> <pre><code>xprop | grep \"NAME\"\n</code></pre>"},{"location":"Operating-Systems/Linux/Misc/window-names/#example","title":"Example","text":"<pre><code>\u276f xprop | grep \"NAME\"\nWM_NAME(STRING) = \"Spotify\"\n_NET_WM_NAME(UTF8_STRING) = \"Spotify\"\n</code></pre>"},{"location":"Operating-Systems/Linux/Networking/Bridge%20Interface/","title":"Create a bridge interface","text":""},{"location":"Operating-Systems/Linux/Networking/Bridge%20Interface/#with-iproute2","title":"With iproute2","text":"<p>Create a new bridge <code>ip link add name bridge_name type bridge</code></p> <p>Set interface to state up <code>ip link set bridge_name up</code></p> <p>Add an interface to the bridge (state of the interface must be up) <code>ip link set eth0 master bridge_name</code></p> <p>Verify bridge <code>bridge link</code></p> <p>Remove interace from a bridge <code>ip link set eth0 nomaster</code></p>"},{"location":"Operating-Systems/Linux/Networking/Bridge%20Interface/#internet-settings","title":"Internet settings","text":"<p>Edit file <code>/etc/systemd/network/mybridge.network</code> <pre><code>[Match]\nName=br0\n\n[Network]\nDHCP=ipv4\n</code></pre></p> <p>Enable, start and reload systemd-networkd <pre><code>sudo systemctl enable systemd-networkd\nsudo systemctl start systemd-networkd\nsudo systemctl reload systemd-networkd\n</code></pre></p>"},{"location":"Operating-Systems/Linux/Networking/dns/","title":"DNS","text":""},{"location":"Operating-Systems/Linux/Networking/dns/#find-local-dns-resolver","title":"Find local DNS resolver","text":"<pre><code>sudo lsof -i :53 -S\n</code></pre>"},{"location":"Operating-Systems/Linux/Networking/network-namespaces/","title":"Linux Network Namespaces","text":""},{"location":"Operating-Systems/Linux/Networking/network-namespaces/#overview","title":"Overview","text":"<p>Linux Network Namespaces provide a powerful and flexible way to isolate network resources within the Linux operating system. This feature allows you to create multiple independent network stacks, each with its own set of network interfaces, routing tables, and firewall rules. Network namespaces are particularly useful for scenarios where you need to create isolated network environments, such as in testing, debugging, or containerization.</p>"},{"location":"Operating-Systems/Linux/Networking/network-namespaces/#key-concepts","title":"Key Concepts","text":""},{"location":"Operating-Systems/Linux/Networking/network-namespaces/#1-network-namespace","title":"1. Network Namespace","text":"<p>A network namespace is an isolated instance of the network stack. It includes its own set of network interfaces, IP addresses, routing tables, and firewall rules. By default, a Linux system has a single global network namespace, and additional namespaces can be created as needed.</p>"},{"location":"Operating-Systems/Linux/Networking/network-namespaces/#2-ip-netns-command","title":"2. ip netns command","text":"<p>The ip netns command is the primary tool for managing network namespaces. It allows you to create, delete, and list namespaces. Additionally, it provides a way to execute commands in a specific namespace context.</p> <p>Example: Creating a Network Namespace</p> <pre><code># Create a network namespace named \"example_ns\"\nsudo ip netns add example_ns\n</code></pre>"},{"location":"Operating-Systems/Linux/Networking/network-namespaces/#3-ip-link-command","title":"3. ip link command","text":"<p>The ip link command is used for managing network interfaces. When working with network namespaces, it allows you to create virtual interfaces that are associated with a specific namespace.</p> <pre><code># Create a virtual Ethernet interface named \"veth0\" in the \"example_ns\" namespace\nsudo ip link add veth0 type veth peer name veth1\nsudo ip link set veth1 netns example_ns\n</code></pre>"},{"location":"Operating-Systems/Linux/Networking/network-namespaces/#4-executing-commands-in-a-namespace","title":"4. Executing Commands in a Namespace","text":"<p>The ip netns exec command is used to execute commands in a specific namespace. This is useful for configuring network settings or running applications within the isolated environment.</p> <pre><code># Run a command (e.g., a shell) in the \"example_ns\" namespace\nsudo ip netns exec example_ns bash\n</code></pre>"},{"location":"Operating-Systems/Linux/Networking/network-namespaces/#5-routing-and-firewall-rules","title":"5. Routing and Firewall Rules","text":"<p>Each network namespace has its own routing table and firewall rules. You can use standard Linux networking tools (ip route, iptables, etc.) to configure these settings within a specific namespace.</p> <pre><code># Add a route to the \"example_ns\" namespace\nsudo ip -n example_ns ip route add default via veth1\n\n# Add a firewall rule to the \"example_ns\" namespace\nsudo ip netns exec iptables -A INPUT -i veth1 -p tcp --dport 80 -j ACCEPT\n</code></pre>"},{"location":"Operating-Systems/Linux/PulseAudio/Volume/","title":"PulseAudio Volume Stuff","text":""},{"location":"Operating-Systems/Linux/PulseAudio/Volume/#find-devices","title":"Find devices","text":"<p><code>t=$(pacmd list-sinks &amp;&amp; pacmd list-sinks &amp;&amp; pacmd list-sources) &amp;&amp; echo $t | grep \"name:\"</code></p>"},{"location":"Operating-Systems/Linux/PulseAudio/Volume/#raise-microphone-volume-with-pacmd","title":"Raise microphone volume with pacmd","text":"<p><code>pacmd set-source-volume alsa_input.usb-Burr-Brown_from_TI_USB_Audio_CODEC-00.analog-stereo 0x25000</code></p>"},{"location":"Operating-Systems/Linux/Window-Manager/i3/bluetooth/","title":"Bluetooth with i3","text":"<p>Install blueman</p> <p>Launch the graphical settings with <code>blueman-manager</code></p>"},{"location":"Operating-Systems/Linux/Window-Manager/i3/dpi/","title":"Change i3 DPI / scaling","text":"<p>put the following configuration into <code>~/.Xresources</code></p> <pre><code>Xft.dpi: 150\n</code></pre> <p>load settings <pre><code>xrdb -merge ~/.Xresources\nexec i3\n</code></pre></p>"},{"location":"Operating-Systems/Linux/Window-Manager/i3/i3-wallpaper/","title":"Wallpaper in i3","text":"<p>feh can be used to display a wallpaper.</p> <p>Define the following in the i3 config file to use a random wallpaper from the path <code>~/wallpaper/</code>.</p> <pre><code>exec --no-startup-id feh --bg-scale --random ~/wallpaper/\n</code></pre>"},{"location":"Operating-Systems/Linux/Window-Manager/i3/spotify/","title":"Control Spotify in i3","text":"<pre><code># spotify player controls\nbindsym XF86AudioPlay exec \"dbus-send --print-reply --dest=org.mpris.MediaPlayer2.spotify /org/mpris/MediaPlayer2 org.mpris.MediaPlayer2.Player.PlayPause\"\nbindsym XF86AudioStop exec \"dbus-send --print-reply --dest=org.mpris.MediaPlayer2.spotify /org/mpris/MediaPlayer2 org.mpris.MediaPlayer2.Player.Stop\"\nbindsym XF86AudioPrev exec \"dbus-send --print-reply --dest=org.mpris.MediaPlayer2.spotify /org/mpris/MediaPlayer2 org.mpris.MediaPlayer2.Player.Previous\"\nbindsym XF86AudioNext exec \"dbus-send --print-reply --dest=org.mpris.MediaPlayer2.spotify /org/mpris/MediaPlayer2 org.mpris.MediaPlayer2.Player.Next\"\n</code></pre>"},{"location":"Operating-Systems/Linux/Window-Manager/i3/volume/","title":"Volume Control in i3","text":"<p>A graphical control for PulseAudio is <code>pavucontrol</code>.</p>"},{"location":"Operating-Systems/Linux/Window-Manager/i3/volume/#keys","title":"Keys","text":"<pre><code># Use pactl to adjust volume in PulseAudio.\nset $refresh_i3status killall -SIGUSR1 i3status\nbindsym XF86AudioRaiseVolume exec --no-startup-id pactl set-sink-volume @DEFAULT_SINK@ +5% &amp;&amp; $refresh_i3status\nbindsym XF86AudioLowerVolume exec --no-startup-id pactl set-sink-volume @DEFAULT_SINK@ -5% &amp;&amp; $refresh_i3status\nbindsym XF86AudioMute exec --no-startup-id pactl set-sink-mute @DEFAULT_SINK@ toggle &amp;&amp; $refresh_i3status\nbindsym XF86AudioMicMute exec --no-startup-id pactl set-source-mute @DEFAULT_SOURCE@ toggle &amp;&amp; $refresh_i3status\n</code></pre>"},{"location":"Operating-Systems/Linux/errors/sendmail-high-cpu/","title":"sendmail process at high cpu usage","text":"<p>I had it sometimes under Alma Linux that after a cronjob fails the sendmail process has a high cpu usage and runs continuously.</p> <pre><code>dnf install esmtp-local-delivery\n</code></pre>"},{"location":"Operating-Systems/Linux/nix/nixpkgs/","title":"nixpkgs","text":""},{"location":"Operating-Systems/Linux/nix/nixpkgs/#get-github-checksums","title":"Get GitHub checksums","text":"<pre><code>nix-prefetch-url --unpack https://github.com/catppuccin/bat/archive/f0dedf515c02799b76a2804db9815a479f6c0075.zip\n</code></pre> <pre><code>REPO=\"\"\n</code></pre> <pre><code>rm -rf /tmp/repo-check\ngit clone --depth 1 \"$REPO\" /tmp/repo-check\ngit -C /tmp/repo-check rev-parse HEAD\nrm -rf /tmp/repo-check/.git\nnix hash path /tmp/repo-check\n</code></pre> <pre><code>fetchFromGitHub {\n  owner = \"owner\";\n  repo = \"repo\";\n  rev = \"65bb66d364e0d10d00bd848a3d35e2755654655b\";\n  hash = \"sha256-8EUDsWeTeZwJNrtjEsUNLMt9I9mjabPRBZG83u7xtPw=\";\n}\n</code></pre>"},{"location":"Operating-Systems/Linux/nix/nixpkgs/#build","title":"Build","text":"<pre><code>nix-build -E 'with import &lt;nixpkgs&gt; {}; callPackage ./default.nix {}'\n</code></pre>"},{"location":"Operating-Systems/Linux/nix/nixpkgs/#test-install","title":"Test-Install","text":"<pre><code>nix-env -iA &lt;package&gt; -f &lt;path to repo&gt;\n</code></pre>"},{"location":"Operating-Systems/Linux/nix/nixpkgs/#submitting-changes","title":"Submitting Changes","text":"<p>https://nixos.org/manual/nixpkgs/stable/#chap-submitting-changes</p>"},{"location":"Operating-Systems/Linux/nix/nixpkgs/#maintainer","title":"Maintainer","text":"<p>Add yourself to the <code>nixpkgs/maintainers/maintainer-list.nix</code> file.</p> <p>Format</p> <pre><code>handle = {\n  # Required\n  name = \"Your name\";\n  email = \"address@example.org\";\n  # Optional\n  matrix = \"@user:example.org\";\n  github = \"GithubUsername\";\n  githubId = your-github-id;\n  keys = [{\n    longkeyid = \"rsa2048/0x0123456789ABCDEF\";\n    fingerprint = \"AAAA BBBB CCCC DDDD EEEE  FFFF 0000 1111 2222 3333\";\n  }];\n};\n</code></pre>"},{"location":"Operating-Systems/Linux/security/selinux/","title":"SELinux","text":""},{"location":"Operating-Systems/Linux/security/selinux/#commands","title":"Commands","text":"<p>See SELinux booleans</p> <pre><code>getsebool -a\n</code></pre> <p>Get messages since 14:05</p> <pre><code>journalctl -t setroubleshoot --since=14:05\n</code></pre>"},{"location":"Operating-Systems/Linux/security/selinux/#inspection","title":"Inspection","text":"<p>Inspect a AVC message</p> <pre><code>sealert -l [message_ID]\n</code></pre>"},{"location":"Operating-Systems/Linux/security/selinux/#flags","title":"Flags","text":"<pre><code>chcon\nrestorecron\n</code></pre>"},{"location":"Operating-Systems/Linux/security/firewall/firewalld/","title":"firewalld","text":""},{"location":"Operating-Systems/Linux/security/firewall/firewalld/#zones","title":"Zones","text":""},{"location":"Operating-Systems/Linux/security/firewall/firewalld/#list-zones","title":"List Zones","text":"<pre><code>firewall-cmd --get-active-zones\n</code></pre>"},{"location":"Operating-Systems/Linux/security/firewall/firewalld/#rules","title":"Rules","text":""},{"location":"Operating-Systems/Linux/security/firewall/firewalld/#ports","title":"Ports","text":"<pre><code>firewall-cmd --permanent --zone=public --add-port=25565/tcp --add-port=19132/udp\n</code></pre> <p>Port Range</p> <pre><code>firewall-cmd --permanent --zone=public --add-port=40000-40030/udp\n</code></pre>"},{"location":"Operating-Systems/Linux/security/firewall/firewalld/#remove-ports","title":"Remove Ports","text":"<pre><code>firewall-cmd --permanent --zone=public --remove-port=25565/tcp --remove-port=19132/udp\n</code></pre> <p>Port Range</p> <pre><code>firewall-cmd --permanent --zone=public --remove-port=40000-40030/udp\n</code></pre>"},{"location":"Operating-Systems/Linux/security/firewall/ufw/","title":"UFW","text":""},{"location":"Operating-Systems/Linux/security/firewall/ufw/#get-status","title":"Get status","text":"<pre><code>ufw status verbose\n</code></pre>"},{"location":"Operating-Systems/Linux/security/firewall/ufw/#rules","title":"Rules","text":""},{"location":"Operating-Systems/Linux/security/firewall/ufw/#ports","title":"Ports","text":"<pre><code>ufw allow 22/tcp\n````\n\n```bash\nufw deny 80/tcp\n````\n\n### Remove Ports\n\n```bash\nufw delete allow 22/tcp\n</code></pre>"},{"location":"Operating-Systems/Linux/security/firewall/ufw/#block-all-incoming-traffic","title":"Block all incoming traffic","text":"<pre><code>ufw default deny incoming\n</code></pre>"},{"location":"Programming/Bash/","title":"Bash","text":""},{"location":"Programming/Bash/#notes","title":"Notes","text":"<ul> <li>The proper she-bang for Bash is <code>#!/usr/bin/env bash</code>.</li> </ul>"},{"location":"Programming/Bash/#links","title":"Links","text":"<ul> <li>Your <code>~/.bashrc</code> doesn't have to be a mess</li> </ul>"},{"location":"Programming/JSON/","title":"JSON","text":""},{"location":"Programming/JSON/#usage","title":"Usage","text":""},{"location":"Programming/JSON/#strings","title":"Strings","text":"<pre><code>{\n    \"my_key\": \"my_string\" \n}\n</code></pre>"},{"location":"Programming/JSON/#integer-and-floats","title":"Integer and floats","text":"<pre><code>{\n    \"my_int\": 2,\n    \"my_float\": 3.5\n}\n</code></pre>"},{"location":"Programming/JSON/#array","title":"Array","text":"<pre><code>{\n    \"my_list\": [\"test\", 5, \"test3\"]\n}\n</code></pre>"},{"location":"Programming/JSON/#objects","title":"Objects","text":"<pre><code>{\n    \"my_object\": {\n        \"name\": \"Test Object\",\n        \"childs\": [\n            {\n                \"name\": \"Child object 1\"\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"Programming/JSON/#links","title":"Links","text":""},{"location":"Programming/YAML/","title":"YAML","text":"<p>YAML is commonly used for configuration files and in applications where data is being stored or transmitted.</p> <p>Filenames can end with <code>.yaml</code> or <code>.yml</code>.</p>"},{"location":"Programming/YAML/#usage","title":"Usage","text":""},{"location":"Programming/YAML/#strings","title":"Strings","text":"<pre><code>---\nkey: this is a string\n\nkey: \"this is also a string\"\n\nkey: |\n  this is a multi-line\n  string with line breaks\n\nkey: &gt;\n  this a multi-line \n  string withouth line breaks\n</code></pre>"},{"location":"Programming/YAML/#integers-and-floats","title":"Integers and floats","text":"<pre><code>---\ninteger: 595\n\nfloat: 12.2\n</code></pre>"},{"location":"Programming/YAML/#lists","title":"Lists","text":"<pre><code>---\nlist1: [1, \"two\", 3]\n\nlist2:\n  - 1\n  - \"two\"\n  - 3\n</code></pre>"},{"location":"Programming/YAML/#objects","title":"Objects","text":"<pre><code>---\nmy_obj:\n  title: My Object\n  description: This is a object\n  childs:\n    - test_obj:\n        name: Test Object\n</code></pre>"},{"location":"Programming/YAML/#comments","title":"Comments","text":"<pre><code>---\n# this is a comment\n</code></pre>"},{"location":"Programming/YAML/#links","title":"Links","text":"<ul> <li>YAML Tutorial: Everything You Need to Get Started in Minutes</li> </ul>"},{"location":"Programming/Go/Build/","title":"Build go binaries","text":""},{"location":"Programming/Go/Build/#linux","title":"Linux","text":"<pre><code>GOOS=linux GOARCH=amd64 go build -v\n</code></pre>"},{"location":"Programming/Go/Build/#windows","title":"Windows","text":"<pre><code>GOOS=windows GOARCH=amd64 go build -v\n</code></pre>"},{"location":"Programming/Go/Build/#helpful-makefile","title":"Helpful Makefile","text":"<pre><code>PROJECT_NAME := \"test-project\"\nPKG := \"github.com/rwxd/$(PROJECT_NAME)\"\nPKG_LIST := $(shell go list ${PKG}/...)\nGO_FILES := $(shell find . -name '*.go' | grep -v _test.go)\n\nhelp:\n    @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-30s\\033[0m %s\\n\", $$1, $$2}'\n\nall: build\n\ntest: ## Test go code\n    @go test -race ./...\n\ndep: ## Get the dependencies\n    @go get -v -d ./...\n\nsetup: ## Install required things\n    python3 -m pip install -r requirements-dev.txt\n    pre-commit install\n\nbuild: dep build-linux build-windows ## Build for all platforms\n\nbuild-linux: dep ## Build for linux\n    @mkdir -p build/\n    @GOOS=linux GOARCH=amd64 go build -o build/ -v $(PKG)\n\nbuild-windows: dep ## Build for windows\n    @mkdir -p build/\n    @GOOS=windows GOARCH=amd64 go build -v -o build/ $(PKG)\n\nclean: ## Remove previous build\n    @rm -rf build/\n</code></pre>"},{"location":"Programming/Go/Concurrency/","title":"Concurrency in Go","text":""},{"location":"Programming/Go/Concurrency/#mutex","title":"Mutex","text":"<p>Safely access data across multiple goroutines</p> <pre><code>func editFile(path string, mu *sync.Mutex){\n    mu.Lock()\n    defer mu.Unlock()\n    // I/O stuff\n}\n</code></pre>"},{"location":"Programming/Go/Formatting/","title":"Formatting in Go","text":"<p>The Go development tools include a command, <code>go fmt</code>, which automatically reformats your code to match the standard format.</p>"},{"location":"Programming/Go/profiling/","title":"Profiling in Go","text":""},{"location":"Programming/Go/profiling/#cpu-profiling","title":"CPU Profiling","text":""},{"location":"Programming/Go/profiling/#generate-data","title":"Generate data","text":"<pre><code>import (\n    \"runtime/pprof\"\n)\n\nfunc main {\n    f, err := os.Create(\"my-tool.prof\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    pprof.StartCPUProfile(f)\n    defer pprof.StopCPUProfile()\n\n    // CPU Intensive code\n}\n</code></pre>"},{"location":"Programming/Go/profiling/#view-data","title":"View data","text":"<pre><code>go tool pprof my-tool.prof\n</code></pre> <pre><code># view top 10 functions\n(pprof) top\n\n# view top 20 functions\n(pprof) top20\n\n# view top 10 functions in a graph\n(pprof) top --cum\n\n# Visualize graph through web browser\n(pprof) web\n\n# Output graph as a svg\n(pprof) svg\n</code></pre>"},{"location":"Programming/Go/profiling/#memory-profiling","title":"Memory Profiling","text":"<p>Go comes with a built-in profiling tool called pprof that can provide detailed information about your application's runtime memory usage.</p>"},{"location":"Programming/Go/profiling/#generate-data_1","title":"Generate data","text":"<pre><code>import _ \"net/http/pprof\"\n</code></pre> <p>Then, add the following code to start a new HTTP server that will serve the pprof endpoints:</p> <pre><code>go func() {\n    log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n}()\n</code></pre> <p>With the above setup, you can access various profiling data by navigating to http://localhost:6060/debug/pprof/ while your application is running. For memory-related insights, http://localhost:6060/debug/pprof/heap is of particular interest.</p>"},{"location":"Programming/Go/profiling/#capture-heap-dump","title":"Capture Heap Dump","text":"<p>Once you have pprof set up and your application is running:</p> <p>Allow your application to run until you suspect a memory leak. Capture a heap profile by executing:</p> <pre><code>curl -s http://localhost:6060/debug/pprof/heap -o mem.pprof\n</code></pre>"},{"location":"Programming/Go/profiling/#analyze-data","title":"Analyze data","text":"<pre><code>go tool pprof mem.pprof\n</code></pre> <ul> <li>Use the top command to get an overview of the functions consuming the most memory.</li> <li>To see detailed memory allocations for a specific function, use the list command followed by the function name.</li> <li>For a visual representation, web or svg commands can be used to generate graphs showcasing memory allocations.</li> </ul>"},{"location":"Programming/Python/Performance%20Analysis/","title":"Profiler","text":"<pre><code>python3 -m cProfile -o log.pstats -m my_module\n</code></pre>"},{"location":"Programming/Python/Performance%20Analysis/#visualisation","title":"Visualisation","text":""},{"location":"Programming/Python/Performance%20Analysis/#gprof2dot-dot-diagram","title":"gprof2dot (Dot Diagram)","text":"<pre><code>sudo pacman -S graphviz\npip3 install gprof2dot\n</code></pre> <pre><code>gprof2dot -f pstats log.pstats | dot -Tsvg -o log.svg\n</code></pre>"},{"location":"Programming/Python/profiling/","title":"Profiling in Python","text":""},{"location":"Programming/Python/profiling/#generate-data","title":"Generate data","text":""},{"location":"Programming/Python/profiling/#pythons-integrated-cprofile","title":"Pythons integrated <code>cProfile</code>","text":"<pre><code>python3 -m cProfile -o profile.pstats -m my_module &lt;args&gt;\n</code></pre>"},{"location":"Programming/Python/profiling/#yappi","title":"Yappi","text":"<p>Yappi supports asynchronous and multithreaded profiling, which is not supported by the built-in profiler.</p> <pre><code>pip3 install -U yappi\n</code></pre> <pre><code>import yappi\nfrom my_module import my_function\n\nyappi.start()\n\nmy_function()\n\nyappi.stop()\n\nyappi.get_func_stats().save(\"profile.pstats\", type=\"pstats\")\n</code></pre>"},{"location":"Programming/Python/profiling/#visualisation","title":"Visualisation","text":""},{"location":"Programming/Python/profiling/#gprof2dot-dot-diagram-svg","title":"gprof2dot (Dot Diagram, SVG)","text":"<p>Transform a <code>.pstats</code> file with gprof2dot into a dot graph as a svg file.</p> <pre><code>pip3 install -U gprof2dot\n</code></pre> <pre><code>gprof2dot -f pstats profile.pstats | dot -Tsvg -o profile.svg\n</code></pre>"},{"location":"Programming/Python/profiling/#snakeviz-interactive","title":"Snakeviz (Interactive)","text":"<p>Snakeviz is a web-based profiling tool which allows users to analyse their code by filtering data by module, function and file, and sorting it according to different criteria such as the number of calls or cumulative time spent in a function.</p> <pre><code>pip3 install -U snakeviz\n</code></pre> <pre><code>snakeviz profile.pstats\n</code></pre>"},{"location":"Programming/Python/profiling/#flamegraph-svg","title":"flamegraph (SVG)","text":"<p>Flame graphs are visual tools that show how much time is spent in each function call. The width of each bar in the graph represents the amount of time spent in that function, with wider bars indicating more time spent and narrower bars indicating less time. The main function is at the bottom, and the subfunctions are stacked vertically on top.</p> <pre><code>pip3 install -U flameprof\n</code></pre> <pre><code>flameprof profile.pstats &gt; profile.svg\n</code></pre>"},{"location":"Programming/Python/ruff/","title":"Ruff","text":""},{"location":"Programming/Python/ruff/#pre-commit-ruff-hooks-on-nixos","title":"Pre-Commit Ruff Hooks on NixOS","text":"<p>Running a <code>ruff</code> pre-commit hook on NixOS will not work, because the installed ruff binary from the pypi package does not work under NixOS.</p> <pre><code>ruff.....................................................................Failed\n- hook id: ruff\n- exit code: 127\n\nCould not start dynamically linked executable: /home/$USER/.cache/pre-commit/repolrdyg6v2/py_env-python3.11/bin/ruff\nNixOS cannot run dynamically linked executables intended for generic\nlinux environments out of the box. For more information, see:\nhttps://nix.dev/permalink/stub-ld\n\nruff-format..............................................................Failed\n- hook id: ruff-format\n- exit code: 127\n\nCould not start dynamically linked executable: /home/$USER/.cache/pre-commit/repolrdyg6v2/py_env-python3.11/bin/ruff\nNixOS cannot run dynamically linked executables intended for generic\nlinux environments out of the box. For more information, see:\nhttps://nix.dev/permalink/stub-ld\n</code></pre> <p>A workaround is removing the downloaded binary and symlinking the installed ruff through nixpkgs.</p> <pre><code>PYPI_RUFF=\"&lt;path to pypi binary&gt;\"; rm \"$PYPI_RUFF\" &amp;&amp; ln -s $(which ruff) \"$PYPI_RUFF\"\n\n# Example\nPYPI_RUFF=\"/home/$USER/.cache/pre-commit/repolrdyg6v2/py_env-python3.11/bin/ruff\"; rm \"$PYPI_RUFF\" &amp;&amp; ln -s $(which ruff) \"$PYPI_RUFF\"\n</code></pre> <p>Links</p> <ul> <li>https://github.com/astral-sh/ruff-pre-commit/issues/22</li> </ul>"},{"location":"Programming/Python/typing-in-python/","title":"Typing in Python","text":"<p>In Python typing can be optionally used. To check typing the standard tool is MyPy.</p>"},{"location":"Programming/Python/typing-in-python/#usage","title":"Usage","text":""},{"location":"Programming/Python/typing-in-python/#function-annotations","title":"Function annotations","text":"<pre><code>def func(arg: arg_type, optarg: arg_type = default) -&gt; return_type: \n...\n</code></pre> <p>For arguments the syntax is <code>argument: annotation</code>, while the return type is annotated using <code>-&gt; annotation</code>. Note that the annotation must be a valid Python expression.</p>"},{"location":"Programming/Python/typing-in-python/#variable-annotations","title":"Variable annotations","text":"<p>Sometimes the type checker needs help in figuring out the types of variables as well. The syntax is similar:</p> <pre><code>pi: float = 3.142\n\ndef circumference(radius: float) -&gt; float:\n    return 2 * pi * radius`\n</code></pre>"},{"location":"Programming/Python/typing-in-python/#links","title":"Links","text":"<ul> <li>Real python article on type checking</li> </ul>"},{"location":"Programming/Python/venvs/","title":"Python Virtual Environments","text":""},{"location":"Programming/Python/venvs/#work-with-virtual-environments","title":"Work with virtual environments","text":"<p>Create a virtual environment <code>python3 -m virtualenv .venv</code> or <code>python3 -m venv .venv</code></p>"},{"location":"Programming/Python/venvs/#links","title":"Links","text":""},{"location":"Programming/Python/Python-Libraries/FastAPI/","title":"FastAPI","text":""},{"location":"Programming/Python/Python-Libraries/Pathlib/","title":"Pathlib","text":""},{"location":"Programming/Python/Python-Libraries/Pathlib/#usage","title":"Usage","text":"<p>Get current path</p> <pre><code>from pathlib import Path\nSTATIC_FILES_DIR = Path(__file__).parent.absolute()\n</code></pre>"},{"location":"Programming/Python/Python-Libraries/Pathlib/#links","title":"Links","text":""},{"location":"Programming/Python/Python-Libraries/PyTest/","title":"PyTest","text":""},{"location":"Programming/Python/Python-Libraries/PyTest/#mocks","title":"Mocks","text":"<p>For mocking with PyTest the <code>unittest.mock</code> library is used.</p>"},{"location":"Programming/Python/Python-Libraries/PyTest/#fixtures","title":"Fixtures","text":""},{"location":"Programming/Python/Python-Libraries/PyTest/#add-parameters-to-fixtures","title":"Add parameters to fixtures","text":"<pre><code>import json\nimport pytest\n\n@pytest.fixture\ndef json_loader():\n    \"\"\"Loads data from JSON file\"\"\"\n\n    def _loader(filename):\n        with open(filename, 'r') as f:\n            print(filename)\n            data = json.load(f)\n        return data\n\n    return _loader\n\n\ndef test_wrong_stop(client, mocker, json_loader):\n    # Arrange\n    get_mock = mocker.MagicMock()\n    get_mock.status_code = 200\n    get_mock.json.return_value = json_loader(\n        cta_error_incorrect_stop_response.json)\n    mocker.patch.object(\n        backend.cta.requests,\n        'get',\n        return_value=get_mock,\n    )\n\n    # Act\n    response = client.simulate_get('/stops/106')\n\n    # Assert\n    assert response.status == falcon.HTTP_200\n    assert response.json == {'error': 'stop_id: 106 does not exist\n</code></pre>"},{"location":"Programming/Python/Python-Libraries/PyTest/#links","title":"Links","text":"<ul> <li>Python Mocks 5 Part Series</li> </ul>"},{"location":"Programming/Rust/Memory%20Management/","title":"Heat","text":""},{"location":"Programming/Rust/Memory%20Management/#stack","title":"Stack","text":""},{"location":"Tools/Anki/","title":"Anki","text":""},{"location":"Tools/Anki/#plugins","title":"Plugins","text":"<ul> <li>Image Occlusion Enhanced</li> <li>Mini Format Pack</li> <li>Review Heatmap</li> <li>Syntax Highlighting for Code</li> </ul>"},{"location":"Tools/Anki/#decks","title":"Decks","text":""},{"location":"Tools/Anki/#links","title":"Links","text":"<ul> <li>How can we develop transformative tools for thought?</li> </ul>"},{"location":"Tools/Audible-Cli/","title":"Audible CLI","text":"<p>https://github.com/mkb79/audible-cli</p>"},{"location":"Tools/Audible-Cli/#setup","title":"Setup","text":""},{"location":"Tools/Audible-Cli/#authfile","title":"Authfile","text":"<pre><code>audible manage auth-file add --password \"&lt;password&gt;\"\n</code></pre>"},{"location":"Tools/Audible-Cli/#profile","title":"Profile","text":"<pre><code>audible manage profile add\n</code></pre>"},{"location":"Tools/Audible-Cli/#download-all-audio-books-to-the-current-directory","title":"Download all audio books to the current directory","text":"<pre><code>audible -P default -v info download --all --aax --ignore-podcasts --jobs 3 --ignore-errors\n</code></pre>"},{"location":"Tools/Audible-Cli/#convert-aax-to-mp3","title":"Convert aax to mp3","text":"<p>https://github.com/KrumpetPirate/AAXtoMP3</p>"},{"location":"Tools/Audible-Cli/#get-the-auth-token-from-audible-cli","title":"Get the auth token from audible-cli","text":"<pre><code>audible -P default activation-bytes\n</code></pre>"},{"location":"Tools/Audible-Cli/#convert-aax-to-mp3_1","title":"Convert aax to mp3","text":"<pre><code>aaxtomp3 -e:mp3 --level 5 -s --authcode &lt;authcode&gt; --loglevel 1 &lt;file.aax&gt;\n</code></pre>"},{"location":"Tools/Audible-Cli/#convert-all-aax-to-mp3","title":"Convert all aax to mp3","text":"<pre><code>find . -name \"*.aax\" -exec aaxtomp3 -e:mp3 --level 5 -s --authcode &lt;authcode&gt; --loglevel 1 --complete_dir &lt;path&gt; {} \\;\n</code></pre>"},{"location":"Tools/Bitwarden/","title":"Bitwarden","text":"<p>Bitwarden is a open source password manager with cloud synchronization and the option to host the sync server on your own hardware.</p>"},{"location":"Tools/Bitwarden/#links","title":"Links","text":"<ul> <li>Self hosting Bitwarden Password Manager</li> </ul>"},{"location":"Tools/Cookiecutter/","title":"Cookiecutter Templates for Projects","text":"<p>Use Jinja2 templating in boilerplates for new projects.</p>"},{"location":"Tools/Cookiecutter/#usage","title":"Usage","text":"<pre><code>python3 -m pip install cookiecutter\ncookiecutter gh:rwxd/cookiecutter-gh-project\n</code></pre>"},{"location":"Tools/HashiCorp-Vault/","title":"HashiCorp Vault","text":"<p>HashiCorp Vault can be used to store things like passwords, certificates and encryption keys.</p>"},{"location":"Tools/HashiCorp-Vault/#usage","title":"Usage","text":""},{"location":"Tools/HashiCorp-Vault/#cli","title":"CLI","text":"<p>Login to a vault server with a token <code>vault login -address=https://vault.net -method=token</code></p> <p>List kv entries <code>vault kv list network/services</code></p> <p>Get a kv entry <code>vault get network/services/ipam</code></p>"},{"location":"Tools/HashiCorp-Vault/#links","title":"Links","text":"<ul> <li>Awesome Vault Tools</li> </ul>"},{"location":"Tools/Headscale/","title":"Headscale","text":"<p>Headscale is a self-hosted, open source implementation of the Tailscale control server.</p>"},{"location":"Tools/Headscale/#connect-a-client-to-the-server","title":"Connect a client to the server","text":""},{"location":"Tools/Headscale/#create-a-user","title":"Create a user","text":"<p>In case you don't have a user yet, you can create one with the following command:</p> <pre><code>headscale users create &lt;user&gt;\n</code></pre>"},{"location":"Tools/Headscale/#get-an-authkey-for-the-user","title":"Get an authkey for the user","text":"<pre><code>headscale --user &lt;user&gt; preauthkeys create --reusable --expiration 1h\n</code></pre>"},{"location":"Tools/Headscale/#authenticate-tailscale-client","title":"Authenticate tailscale client","text":"<pre><code>tailscale up --login-server &lt;headscale url&gt; --authkey &lt;authkey&gt;\n</code></pre>"},{"location":"Tools/Headscale/#check-status","title":"Check status","text":"<pre><code>tailscale status\n</code></pre>"},{"location":"Tools/KeepassXC/","title":"KeePassXC","text":"<p>KeePassXC is a open source password manager which uses a local password database file.</p> <p>To sync the database with different devices an external cloud service like Dropbox or OneDrive is needed.</p> <p>KeePassXC has the functionality to store SSH keys and inject the keys into the SSH agent.</p>"},{"location":"Tools/KeepassXC/#links","title":"Links","text":"<ul> <li>Getting started</li> <li>Using KeePassXC to manage SSH keys</li> <li>Authentication</li> </ul>"},{"location":"Tools/MkDocs/","title":"MkDocs","text":"<p>MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. --  https://www.mkdocs.org/ </p>"},{"location":"Tools/MkDocs/#usage","title":"Usage","text":"<p>View the website local with: <code>mkdocs serve</code>.</p> <p>Build the website with: <code>mkdocs build</code>.</p> <p>The default export directory is <code>./site</code>.</p>"},{"location":"Tools/MkDocs/#plugins","title":"Plugins","text":""},{"location":"Tools/MkDocs/#links","title":"Links","text":"<ul> <li>mkdocs-material</li> </ul>"},{"location":"Tools/Task/","title":"Task","text":"<p>Task is a runner / built tool. </p> <p>The configuration is written in a <code>Taskfile.yml</code></p> <p>Taskfile Template <pre><code># https://taskfile.dev  \n\nversion: '3'  \n\nvars:  \nGREETING: Hello, World!  \n\ntasks:  \ndefault:  \ncmds:  \n- echo \"{{.GREETING}}\"  \nsilent: true\n</code></pre></p>"},{"location":"Tools/Task/#usage","title":"Usage","text":"<p>Init a Taskfile template  <code>task --init</code></p> <p>List tasks <code>task -l</code> or <code>task --list</code></p> <p>Use vars at global or task level <pre><code>vars:\n  CONTAINER_NAME: wiki.rwxd.eu\n  CURRENT_DIR:\n    sh: pwd\n  SITE_DIR: \"{{.CURRENT_DIR}}/site\"\n</code></pre></p>"},{"location":"Tools/Task/#links","title":"Links","text":""},{"location":"Tools/autorestic/","title":"autorestic - High backup level CLI utility for restic.","text":"<p>Documentation</p> <p>The commands will work with the configuration saved to <code>~/.autorestic.yaml</code> you can also specify a different config file with the <code>-c</code> flag.</p> <p>The <code>--ci</code> flag is used for the <code>exec</code> command to prevent colors from being printed.</p>"},{"location":"Tools/autorestic/#init-backend","title":"Init backend","text":"<pre><code>autorestic check\n</code></pre>"},{"location":"Tools/autorestic/#backup","title":"Backup","text":"<pre><code># all\nautorestic backup --all\n\n# specific locations\nautorestic backup --locations \"&lt;location1&gt;,&lt;location2&gt;\"\n</code></pre>"},{"location":"Tools/autorestic/#show-stats-for-a-backend","title":"Show stats for a backend","text":"<pre><code>autorestic --ci exec -vb &lt;backend&gt; stats\n</code></pre>"},{"location":"Tools/autorestic/#show-snapshots-for-a-backend","title":"Show snapshots for a backend","text":"<pre><code>autorestic --ci exec -vb &lt;backend&gt; snapshots\n</code></pre>"},{"location":"Tools/autorestic/#check-a-backend-for-errors","title":"Check a backend for errors","text":"<pre><code>autorestic --ci exec -vb &lt;backend&gt; check\n</code></pre>"},{"location":"Tools/autorestic/#mount-repository-on-backend","title":"Mount repository on backend","text":"<pre><code>mkdir -p /mnt/restic\nautorestic --ci exec -vb &lt;backend&gt; mount -- /mnt/restic\n</code></pre>"},{"location":"Tools/borg/","title":"Borg","text":""},{"location":"Tools/borg/#delete-directory-from-all-backups","title":"Delete directory from all backups","text":"<p>Dry-Run</p> <pre><code>borg recreate &lt;archive&gt; --dry-run --list --verbose --exclude &lt;path&gt;\n</code></pre> <p>Delete</p> <pre><code>borg recreate &lt;archive&gt; --list --verbose --exclude &lt;path&gt;\n</code></pre>"},{"location":"Tools/cht.sh/","title":"cht.sh","text":""},{"location":"Tools/cht.sh/#links","title":"Links","text":"<ul> <li>Installation</li> <li>Tab completion</li> </ul>"},{"location":"Tools/mermaid/","title":"Mermaid","text":"<pre><code>sequenceDiagram\nAlice-&gt;&gt;John: Hello John, how are you?\nloop Healthcheck\n    John-&gt;&gt;John: Fight against hypochondria\nend\nNote right of John: Rational thoughts!\nJohn--&gt;&gt;Alice: Great!\nJohn-&gt;&gt;Bob: How about you?\nBob--&gt;&gt;John: Jolly good!\n</code></pre>"},{"location":"Tools/openssl/","title":"Open SSL","text":""},{"location":"Tools/openssl/#generate-passwords","title":"Generate passwords","text":"<p><code>openssl passwd -6 -salt xyz</code></p>"},{"location":"Tools/spicetify/","title":"Change Spotify Theme with spicetify-cli","text":""},{"location":"Tools/spicetify/#install","title":"Install","text":"<p>Arch <code>yay -S spicetify-cli</code></p>"},{"location":"Tools/spicetify/#usage","title":"usage","text":"<p>generate config <code>spicetify</code></p> <p>apply config <pre><code>spicetify backup apply\nspicetify apply\n</code></pre></p> <p>change theme <code>spicetify config current_theme THEME_NAME</code></p> <p>change color scheme <code>spicetify config color_scheme SCHEME_NAME</code></p>"},{"location":"Tools/spicetify/#help","title":"help","text":"<p>when Spotify is installed through AUR <pre><code>sudo chmod a+wr /opt/spotify\nsudo chmod a+wr /opt/spotify/Apps -R\n</code></pre></p>"},{"location":"Tools/spicetify/#links","title":"Links","text":"<ul> <li>spicetify-cli</li> <li>spicetify themes</li> </ul>"},{"location":"Tools/Git/bfg-repo-cleaner/","title":"Clean Git repositories with BFG","text":"<p>With BFG large or troublesome files can be removed from a Git Repository</p> <p>The Git repo should be cloned with <code>--mirror</code></p>"},{"location":"Tools/Git/bfg-repo-cleaner/#files","title":"Files","text":"<p>Delete a file in a Git repository and force push the new commit history.</p> <pre><code>bfg --delete-files file.md\ngit reflog expire --expire=now --all &amp;&amp; git gc --prune=now --aggressive\ngit push --force\n</code></pre>"},{"location":"Tools/Git/bfg-repo-cleaner/#secrest","title":"Secrest","text":"<p>A file with a list of secrets can be used to remove all occurrences in the git repository</p> <p><code>leaked-passwords.txt</code></p> <pre><code>PASSWORD1                       # Replace literal string 'PASSWORD1' with '***REMOVED***' (default)\nPASSWORD2==&gt;examplePass         # replace with 'examplePass' instead\nPASSWORD3==&gt;                    # replace with the empty string\nregex:password=\\w+==&gt;password=  # Replace, using a regex\nregex:\\r(\\n)==&gt;$1               # Replace Windows newlines with Unix newlines\n</code></pre> <pre><code>bfg --replace-text leaked-passwords.txt\n</code></pre> <pre><code>git reflog expire --expire=now --all &amp;&amp; git gc --prune=now --aggressive\n</code></pre>"},{"location":"Tools/Git/git-crypt/","title":"Git Crypt","text":""},{"location":"Tools/Git/git-crypt/#how-to","title":"How to","text":""},{"location":"Tools/Git/git-crypt/#init","title":"Init","text":"<p>Initialize repository with <code>git-crypt init</code></p>"},{"location":"Tools/Git/git-crypt/#files-to-encrypt","title":"Files to encrypt","text":"<p>Create a <code>.gitattributes</code> file</p> <pre><code>touch .gitattributes\n</code></pre> <p>The <code>.gitattatributes</code> file contains lines in the following form:</p> <pre><code>[file pattern] attr1=value1 attr2=value2\n</code></pre>"},{"location":"Tools/Git/git-crypt/#example","title":"Example","text":"<p>If we want to encrypt the file <code>config.yml</code>, the <code>.gitattatributes</code> should contain the following:</p> <pre><code>config.yml filter=git-crypt diff=git-crypt\n</code></pre> <p>With <code>git-crypt status</code> we can see that our file will be encrypted on push to our remote repository.</p> <pre><code>\u276f git-crypt status | grep \"config.yml\"\n    encrypted: config.yml\n</code></pre>"},{"location":"Tools/Git/git-crypt/#locking","title":"Locking","text":"<p>With <code>git-crypt lock</code> and <code>git-crypt unlock</code> the repository can be unlocked at will.</p>"},{"location":"Tools/Git/git-crypt/#adding-additional-users-with-gpg-keys","title":"Adding additional users with gpg keys","text":"<p><code>git-crypt add-gpg-user KEYID</code></p>"},{"location":"Tools/Git/git/","title":"Git","text":""},{"location":"Tools/Git/git/#links","title":"Links","text":"<ul> <li>Write yourself a Git</li> <li>DIY Git in Python</li> <li>Git in Go</li> </ul>"},{"location":"Tools/Git/gitleak/","title":"Gitleak","text":""},{"location":"Tools/Git/gitleak/#scan-current-git-repository","title":"Scan current git repository","text":"<pre><code>docker run -v \"$PWD\":/path ghcr.io/zricethezav/gitleaks:v8.8.12 detect -f json -r \"/path/report-secrets.json\" --source=\"/path\"\n</code></pre> <p>Extract unique secrets to <code>extracted-secrets</code></p> <pre><code>cat report-secrets.json | jq -n -r 'inputs[].Secret' | sort -u &gt; extracted-secrets\n</code></pre>"},{"location":"Tools/Git/gitleak/#clear-secrets-from-repository","title":"Clear secrets from repository","text":"<p>Use (bfg)[../bfg-repo-cleaner.md]</p> <p>Prepare with:</p> <pre><code>bfg --replace-text extracted-secrets\n</code></pre> <p>Clean secrets with:</p> <pre><code>git reflog expire --expire=now --all &amp;&amp; git gc --prune=now --aggressive\n</code></pre>"},{"location":"Tools/Git/GitLab/access-tokens/","title":"GitLab Access Tokens","text":""},{"location":"Tools/Git/GitLab/access-tokens/#clone","title":"Clone","text":"<p>Clone with an access token <code>git clone https://$project_name:$token@$gitlab/$project_path.git</code></p>"},{"location":"Tools/NeoVIM/Coc/","title":"Coc in Neovim","text":""},{"location":"Tools/NeoVIM/Coc/#coc-plugins","title":"Coc Plugins","text":"<p>Use in init.vim <pre><code>let g:coc_global_extensions = [\n            \\ 'coc-pyright',\n            \\ 'coc-prettier',\n            \\ 'coc-git',\n            \\ 'coc-json',\n            \\ 'coc-docker',\n            \\ 'coc-yaml',\n            \\ 'coc-html',\n            \\ 'coc-sh',\n            \\ 'coc-go',\n            \\ '@yaegassy/coc-ansible',\n            \\ ]\n</code></pre></p>"},{"location":"Tools/PlantUML/PlantUML%20Themes/","title":"PlantUML Themes","text":"<p>An overview of all available themes can be seen in the Theme Gallery.</p>"},{"location":"Tools/PlantUML/PlantUML%20Themes/#usage","title":"Usage","text":"<p>Set a theme </p> <p></p> <p>Get all themes with <code>help themes</code></p> <p></p>"},{"location":"Tools/PlantUML/PlantUML%20Themes/#links","title":"Links","text":"<ul> <li>plantuml.com/en/theme</li> </ul>"},{"location":"Tools/VS-Code/Plugins/","title":"VS Code Plugins","text":""},{"location":"Tools/VS-Code/Plugins/#list","title":"List","text":"<ul> <li>PlantUML</li> </ul>"},{"location":"Tools/VS-Code/Plugins/#links","title":"Links","text":"<ul> <li>Best VS Code Extensions 2021</li> <li>Awesome VS Code</li> </ul>"},{"location":"Tools/Vim/Comment%20out%20code/","title":"Comment out code with VIM","text":"<ol> <li>select the first character of your block</li> <li>press crtl + v (rectangular visual selectionn mode)</li> <li>type j for each line you want to be commented</li> <li>type shift + i (\"insert at start\")</li> <li>type #</li> <li>end with ESC </li> </ol>"},{"location":"Tools/Vim/copy%20all/","title":"Copy all","text":"<p><code>g g \" + y G</code></p> <p><code>%y+</code></p>"},{"location":"Virtualization/ProxMox/proxmox-8-apt-updates/","title":"Configure apt repository updates on Proxmox 8.x.x Community Edition","text":""},{"location":"Virtualization/ProxMox/proxmox-8-apt-updates/#add-the-proxmox-repositoy-to-etcaptsourceslistdpve-communitylist","title":"Add the Proxmox repositoy to /etc/apt/sources.list.d/pve-community.list","text":"<pre><code>echo \"deb http://download.proxmox.com/debian/pve bookworm pve-no-subscription\" &gt; /etc/apt/sources.list.d/pve-community.list\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-8-apt-updates/#comment-out-the-enterprise-repository-at-etcaptsourceslistdpve-enterpriselist","title":"Comment out the enterprise repository at /etc/apt/sources.list.d/pve-enterprise.list","text":"<pre><code>sed -i 's/^deb/#deb/' /etc/apt/sources.list.d/pve-enterprise.list\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-8-apt-updates/#change-the-ceph-repository-at-etcaptsourceslistdcephlist","title":"Change the ceph repository at /etc/apt/sources.list.d/ceph.list","text":"<pre><code>sed -i 's/^deb/#deb/' /etc/apt/sources.list.d/ceph.list\necho \"deb http://download.proxmox.com/debian/ceph-quincy bookworm no-subscription\" &gt;&gt; /etc/apt/sources.list.d/ceph.list\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-cpu-consumption/","title":"Reduce CPU consumption on Proxmox","text":"<ol> <li>Login to the Proxmox host via the web interface by pressing on Shell</li> <li>Install the package <code>cpufrequtils</code> via <code>apt install cpufrequtils</code> <pre><code>apt update &amp;&amp; apt install cpufrequtils\n</code></pre></li> <li>See available governors via <code>cpufreq-info -g</code> <pre><code>cpufreq-info -g\n</code></pre></li> <li>See current governor     <pre><code>cpufreq-info -p\n</code></pre></li> <li>Set the governor to <code>powersave</code> via <code>cpufreq-set -g powersave</code> <pre><code>cpufreq-set -g powersave\n</code></pre></li> <li>Make it persistent     <pre><code>echo 'GOVERNOR=\"powersave\"' |  tee /etc/default/cpufrequtils\n</code></pre></li> </ol>"},{"location":"Virtualization/ProxMox/proxmox-energy-consumption/","title":"Reduce energy consumption of Proxmox","text":""},{"location":"Virtualization/ProxMox/proxmox-energy-consumption/#powertop","title":"Powertop","text":"<p>Powertop is a tool to diagnose issues with power consumption and power management. It can also be used to tune power management settings.</p>"},{"location":"Virtualization/ProxMox/proxmox-energy-consumption/#install-powertop","title":"Install powertop","text":"<pre><code>apt install powertop\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-energy-consumption/#run-powertop-calibration","title":"Run powertop calibration","text":"<p>Calibration will toggle various functions on and off to determine the best settings for your system. So it is best to run this when the system is idle.</p> <pre><code>powertop --calibrate\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-energy-consumption/#run-powertop-to-see-recommendations","title":"Run powertop to see recommendations","text":"<p>With  you can switch between the different tabs. <pre><code>powertop\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-energy-consumption/#auto-tune-power-management-settings-not-reboot-persistent","title":"Auto tune power management settings (not reboot persistent)","text":"<pre><code>powertop --auto-tune\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-energy-consumption/#systemd-service-to-auto-tune-power-management-settings-reboot-persistent","title":"Systemd service to auto tune power management settings (reboot persistent)","text":"<pre><code>cat &lt;&lt; EOF &gt; /etc/systemd/system/powertop.service\n[Unit]\nDescription=Powertop tunings\n\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecStart=/usr/sbin/powertop --auto-tune\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\nsystemctl enable --now powertop.service\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-passtrough-hard-drive/","title":"Passtrough a hard drive from the Proxmox host to a VM","text":""},{"location":"Virtualization/ProxMox/proxmox-passtrough-hard-drive/#find-the-hard-drive-copy-the-uuid","title":"Find the hard drive &amp; copy the UUID","text":"<pre><code>lsblk -o NAME,SIZE,TYPE,FSTYPE,MOUNTPOINT,MODEL\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-passtrough-hard-drive/#find-the-vm-id","title":"Find the vm id","text":"<pre><code>qm list\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-passtrough-hard-drive/#passtrough-the-hard-drive-as-scsi","title":"Passtrough the hard drive as scsi","text":"<pre><code>qm set $vm_id -scsi2 /dev/disk/by-uuid/$disk_uuid\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-passtrough-hard-drive/#restart-the-vm","title":"Restart the vm","text":"<pre><code>qm reboot $vm_id\n</code></pre>"},{"location":"Virtualization/ProxMox/proxmox-passtrough-hard-drive/#in-case-it-should-be-removed","title":"In case it should be removed","text":"<pre><code>qm unlink $vm_id --idlist scsi2\n</code></pre>"}]}